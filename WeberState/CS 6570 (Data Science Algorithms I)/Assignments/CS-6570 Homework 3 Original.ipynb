{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c4b840-0b7d-4db8-a8b2-967164fc779d",
   "metadata": {},
   "source": [
    "# CS-6570 Assignment 3 - Variable Selection\n",
    "\n",
    "*Weber State University*\n",
    "\n",
    "**Your Name**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392b820-1620-4fb7-a184-f6c134a8e712",
   "metadata": {},
   "source": [
    "For this assignment we're going to build and attempt to optimize regression models using some of the techniques we're learned so far in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914731b0-58d5-42f9-8b7d-e9943228d287",
   "metadata": {},
   "source": [
    "First, let's import our favorite libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cf1857-c29f-425e-9d28-3a080ef3034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5815276-1b4e-4050-8c94-748cdccf21a7",
   "metadata": {},
   "source": [
    "There are also some libraries and functions we'll need for creating and testing our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8a6f64-3798-4f47-923d-03cdad7ec79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e68666-6371-4b7f-8d33-64e3e54c59bc",
   "metadata": {},
   "source": [
    "The dataset we'll use for this is the \"Hitters\" dataset (\"Hitters.csv\"), which is a dataset of Major League Baseball player statistics from 1986-1987. More info about the dataset can be found [here](https://www.kaggle.com/datasets/floser/hitters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf81aa21-09f8-4200-a68e-830e7c33bff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>...</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-Andy Allanson</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>446</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Alan Ashby</td>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>...</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-Alvin Davis</td>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>...</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-Andre Dawson</td>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>...</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-Andres Galarraga</td>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0  AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  \\\n",
       "0     -Andy Allanson    293    66      1    30   29     14      1     293   \n",
       "1        -Alan Ashby    315    81      7    24   38     39     14    3449   \n",
       "2       -Alvin Davis    479   130     18    66   72     76      3    1624   \n",
       "3      -Andre Dawson    496   141     20    65   78     37     11    5628   \n",
       "4  -Andres Galarraga    321    87     10    39   42     30      2     396   \n",
       "\n",
       "   CHits  ...  CRuns  CRBI  CWalks  League Division PutOuts  Assists  Errors  \\\n",
       "0     66  ...     30    29      14       A        E     446       33      20   \n",
       "1    835  ...    321   414     375       N        W     632       43      10   \n",
       "2    457  ...    224   266     263       A        W     880       82      14   \n",
       "3   1575  ...    828   838     354       N        E     200       11       3   \n",
       "4    101  ...     48    46      33       N        E     805       40       4   \n",
       "\n",
       "   Salary  NewLeague  \n",
       "0     NaN          A  \n",
       "1   475.0          N  \n",
       "2   480.0          A  \n",
       "3   500.0          N  \n",
       "4    91.5          N  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hitters = pd.read_csv('Datasets/Hitters.csv')\n",
    "df_hitters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a48276-3c52-453a-a352-2fefb5cebdb0",
   "metadata": {},
   "source": [
    "Let's rename that first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5856bab-4d16-48c0-9729-8b3d33349e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hitters.rename(columns={\"Unnamed: 0\": \"Player\"}, inplace=True) #Name the first column \"Player\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ae974-8b53-4f67-8f46-d85aa500b0de",
   "metadata": {},
   "source": [
    "Note that the Salary variable is missing for some of the players. The isnull() function can be used to identify the missing observations. It returns a vector of the same length as the input vector, with a TRUE value for any elements that are missing, and a FALSE value for non-missing elements. The sum() function can then be used to count all of the missing elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3baaab21-fad3-46ae-a099-d57716da256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values: 59\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of null values:\", df_hitters[\"Salary\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e4987-8c5d-4e7d-8522-298a9b921fa4",
   "metadata": {},
   "source": [
    "We see that Salary is missing for 59 players. That's not too many. Let's drop them. The dropna() function removes all of the rows that have missing values in any variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20214ecd-57c3-4e6e-a9f0-53ba4619e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of original data: (322, 21)\n",
      "Dimensions of modified data: (263, 21)\n",
      "Number of null values: 0\n"
     ]
    }
   ],
   "source": [
    "# Print the dimensions of the original Hitters data (322 rows x 20 columns)\n",
    "print(\"Dimensions of original data:\", df_hitters.shape)\n",
    "\n",
    "# Drop any rows the contain missing values, along with the player names\n",
    "df_hitters_clean = df_hitters.dropna()\n",
    "\n",
    "# Print the dimensions of the modified Hitters data (263 rows x 20 columns)\n",
    "print(\"Dimensions of modified data:\", df_hitters_clean.shape)\n",
    "\n",
    "# One last check: should return 0\n",
    "print(\"Number of null values:\", df_hitters_clean[\"Salary\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d2e923-3f3a-4542-8380-11cb0f41cc84",
   "metadata": {},
   "source": [
    "Alright, so we've now dropped all the rows with missing data.\n",
    "\n",
    "Some of our predictors are categorical, so for this exercise we'll eliminate those. We'll also specify the variable, \"Salary\", that we're trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6161a472-b30a-4773-bc21-bc343e399319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2703</td>\n",
       "      <td>806</td>\n",
       "      <td>32</td>\n",
       "      <td>379</td>\n",
       "      <td>311</td>\n",
       "      <td>138</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>5511</td>\n",
       "      <td>1511</td>\n",
       "      <td>39</td>\n",
       "      <td>897</td>\n",
       "      <td>451</td>\n",
       "      <td>875</td>\n",
       "      <td>313</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1700</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>217</td>\n",
       "      <td>93</td>\n",
       "      <td>146</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>3198</td>\n",
       "      <td>857</td>\n",
       "      <td>97</td>\n",
       "      <td>470</td>\n",
       "      <td>420</td>\n",
       "      <td>332</td>\n",
       "      <td>1314</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>4908</td>\n",
       "      <td>1457</td>\n",
       "      <td>30</td>\n",
       "      <td>775</td>\n",
       "      <td>357</td>\n",
       "      <td>249</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  \\\n",
       "1      315    81      7    24   38     39     14    3449    835      69   \n",
       "2      479   130     18    66   72     76      3    1624    457      63   \n",
       "3      496   141     20    65   78     37     11    5628   1575     225   \n",
       "4      321    87     10    39   42     30      2     396    101      12   \n",
       "5      594   169      4    74   51     35     11    4408   1133      19   \n",
       "..     ...   ...    ...   ...  ...    ...    ...     ...    ...     ...   \n",
       "317    497   127      7    65   48     37      5    2703    806      32   \n",
       "318    492   136      5    76   50     94     12    5511   1511      39   \n",
       "319    475   126      3    61   43     52      6    1700    433       7   \n",
       "320    573   144      9    85   60     78      8    3198    857      97   \n",
       "321    631   170      9    77   44     31     11    4908   1457      30   \n",
       "\n",
       "     CRuns  CRBI  CWalks  PutOuts  Assists  Errors  \n",
       "1      321   414     375      632       43      10  \n",
       "2      224   266     263      880       82      14  \n",
       "3      828   838     354      200       11       3  \n",
       "4       48    46      33      805       40       4  \n",
       "5      501   336     194      282      421      25  \n",
       "..     ...   ...     ...      ...      ...     ...  \n",
       "317    379   311     138      325        9       3  \n",
       "318    897   451     875      313      381      20  \n",
       "319    217    93     146       37      113       7  \n",
       "320    470   420     332     1314      131      12  \n",
       "321    775   357     249      408        4       3  \n",
       "\n",
       "[263 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the response variable.\n",
    "y = df_hitters_clean.Salary\n",
    "\n",
    "# Drop the column with the independent variable (Salary), and the columns with categorical data\n",
    "#The axis=1 parameter specifies we're dropping columns, and not rows.\n",
    "X = df_hitters_clean.drop(['Salary', 'League', 'Division', 'NewLeague', 'Player'], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb40ce1-458c-468a-98a3-6d0c421c5b41",
   "metadata": {},
   "source": [
    "Now, for this assignment we're going to create a subset that will be our training data, and a subset that will be our test data. Let's do an 80/20 split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faf91e60-0f54-43de-a5e2-f2760c5743cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e517a-1c97-4a49-a236-9f6e9817a6c3",
   "metadata": {},
   "source": [
    "## Backward Subset Selection ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc46611-f740-4727-949d-a2fb4050a393",
   "metadata": {},
   "source": [
    "If we build a linear model with all these inputs, we'll likely overfit the model. To avoid this, we'd like to build a model using only the most important variables. But, which subset of variables is most important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2effdb-e7ea-4da3-b89a-44bfeb702500",
   "metadata": {},
   "source": [
    "In lecture 9, we learned three methods for selecting the best subset of variables for a linear model:\n",
    "\n",
    "* Best subset selection\n",
    "* Forward stepwise selection\n",
    "* Backward stepwised selection\n",
    "\n",
    "We went over algorithms for each of these, and implemented two (best subset and forward stepwise) as Python code. In this assignment, you'll implement backward stepwise selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80135c-05c7-4c16-9144-1fcac6538536",
   "metadata": {},
   "source": [
    "The basic algorithm for backward stepwise selection is:\n",
    "\n",
    "_Algorithm_\n",
    "\n",
    "- Let $M_{p}$ denote the full model which contains all $p$ predictors.\n",
    "\n",
    "- For $k=p,p-1,...,1$\n",
    "    - Consider all $k$ models that contain all but one of the predictors in $M_{k}$, for a total of $k-1$ predictors.\n",
    "    - Pick the best among these $k$ models, and call in $M_{k-1}$. Here can define _best_ as having the smallest $RSS$ or highest $R^{2}$\n",
    "- Select the single best model among $M_{0},M_{1},...,M_{n}$ using $C_{p}$, $BIC$, adjusted $R^{2}$ or any other method.\n",
    "\n",
    "For this assignment, use the largest $R^{2}$ to determine the best model at each step, and select the overall best model using the adjusted $R^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c560ee-e964-4636-8f95-ba351fee86d7",
   "metadata": {},
   "source": [
    "We'll start out with a list of all the predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d331a2ed-073b-49ea-aed8-77fa2286a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "backwards_features = list(X.columns)\n",
    "p = len(backwards_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe5a75c-c970-4472-9601-4c0ab3d3e387",
   "metadata": {},
   "source": [
    "We'll also create two empty lists that you should fill:\n",
    "* *R2_list_backwards* - Fill this with the best $R^{2}$ value that you find at each step.\n",
    "* *features_list_backwards* - Fill this with the best set of features that you find at each step.\n",
    "* *R2_test_list_backwards* - Fill this with the performance of the model on the test data using the best set of features found at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3820c0bd-80e8-4650-a78e-5d467bf62e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_list_backwards, features_list_backwards, R2_test_list_backwards = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3099b8c-338e-4dfe-b705-b2ce8d2f1209",
   "metadata": {},
   "source": [
    "Alright, now it's time for you to write your own code! Write code that appropriately populates the two lists just created. However, do so using just the *X_train* and *y_train* datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2bc429e-e1de-4036-85fb-cba8eaf461f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Implement the backward subset selection algorithm\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d61483-50cd-4180-aa7d-94701fc575dc",
   "metadata": {},
   "source": [
    "Next, create a dataframe with four columns: the feature list, $R^{2}$ values, and test $R^{2}$ values lists you just created, plus another column that records the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7c492-34d1-4a22-a0cf-cc7d27dc2b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create a dataframe consisting of the feature list, the R^2 values, and the number of features for each submodel $M_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18e39ef-5066-4e5b-9d56-ccba16e1e021",
   "metadata": {},
   "source": [
    "Finally, plot the adjusted $R^{2}$ values for each set of predictor variables, with the number of predictor variables on the $x$-axis. Mark the maximum, and print the predictors associated with that maximum.\n",
    "\n",
    "Recall that the adjusted $R^{2}$ is defined as:\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle R^{2}_{a} = 1-\\frac{RSS/(n-k-1)}{TSS/n-1}$\n",
    "</center>\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a64684-f410-4797-8710-49f7fb703afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the adjusted R^2 values for the number of predictor variables, mark the maximum, and print the predictors associated with that maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b01f11-71ac-469c-9f1b-fa3cf6ca91e6",
   "metadata": {},
   "source": [
    "Alright! Now, let's check if the number of predictors we determined using the adjusted $R^{2}$ value actually does the best on our test data.\n",
    "\n",
    "To do this, plot the actual $R^{2}$ value for each set of predictor variables when run on the test data. Again, make the x-axis the number of predictors, mark the maximum, and print the predictors associated with that maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68c870-b529-4e1b-b877-be753f654a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the R^2 values for the given number of predictor variables when the model is run on the test data. Mark the maximum, and print the predictors associated with that maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d70c5ea-4963-411b-8d4c-5bdcc683244c",
   "metadata": {},
   "source": [
    "Now, plot both on the same line charts on the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece7197d-61b6-43d3-802f-640bce0ab701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot both line charts on the same figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cebf9ae-8956-43a9-a4cc-79f773158f9e",
   "metadata": {},
   "source": [
    "Do the best subset of predictors found using adjusted $R^{2}$ match those found using a test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae7f6c-9e2e-4573-ab89-db8e578dfb16",
   "metadata": {},
   "source": [
    "## Ridge and Lasso Regression ##\n",
    "\n",
    "Next, we'll take a look at ridge and lasso regression for this hitters dataset. We'll use ridge regression as an example, and then you should do something similar for lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb9162e-0768-420e-839d-f2b4e2e37f50",
   "metadata": {},
   "source": [
    "**Ridge Regression**\n",
    "\n",
    "We'll first investigate building a predictive salary model using ridge regression.\n",
    "\n",
    "To do this, first we'll create a set of 90 values for our hyperparameter $\\lambda$ as we did in Lectures 9 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1588d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = 10**np.linspace(7,-2,90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ceb3b-4074-4e93-a741-7ecca08ae331",
   "metadata": {},
   "source": [
    "Now, we'll calculate the values of our coefficients for each value of $\\lambda$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8351bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "coefs = [] #Keep track of the coefficients.\n",
    "\n",
    "for l in lambdas:\n",
    "    ridge.set_params(alpha = l) #Ridge regression in Python calls the lambda term alpha.\n",
    "    ridge.fit(X, y)\n",
    "    coefs.append(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb510f9-4163-44e4-a28e-dd375b8df1c7",
   "metadata": {},
   "source": [
    "We can plot how these coefficients change as $\\lambda$ increases, noting they should approach but not equal $0$ as $\\lambda$ gets large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111dd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(lambdas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc472c0-e12a-4eb4-86db-a16d2bdec21b",
   "metadata": {},
   "source": [
    "We can use the RidgeCV function to determine an optimal value for $\\lambda$ based on leave-one-out cross-validation (LOOCV):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c1b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv = RidgeCV(alphas = lambdas)\n",
    "ridgecv.fit(X, y)\n",
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aadb658-83fd-4ef0-a3f7-00e358c52ca9",
   "metadata": {},
   "source": [
    "Building a ridge regression model with this optimal $\\lambda$, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab75cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge2 = Ridge(alpha = ridgecv.alpha_)\n",
    "ridge2.fit(X, y)\n",
    "print(pd.Series(ridge2.coef_, index = X.columns))\n",
    "mean_squared_error(y, ridge2.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c118072-4bb0-4629-a7fc-2237f3f55329",
   "metadata": {},
   "source": [
    "For $3$-fold cross-validation we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7948e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv = RidgeCV(alphas = lambdas, cv=3)\n",
    "ridgecv.fit(X, y)\n",
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac60ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge3 = Ridge(alpha = ridgecv.alpha_)\n",
    "ridge3.fit(X, y)\n",
    "print(pd.Series(ridge3.coef_, index = X.columns))\n",
    "mean_squared_error(y, ridge3.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b4011-6029-4eff-b861-046f0d5bdebc",
   "metadata": {},
   "source": [
    "For the next part of this homework assignment, you'll investigate the same modeling question using lasso regression and the LassoCV function. Check out the optimal $\\lambda$ values you get for lasso regression with LOOCV and 3-fold CV, and note which coefficients are set to $0$ is each case.\n",
    "\n",
    "Specifically, you should:\n",
    "\n",
    "1. Plot how the weights change for lasso regression as $\\lambda$ gets large.\n",
    "2. Calculate the optimal value of $\\lambda$, and the corresponding model coefficients, using LOOCV.\n",
    "3. Calculate the optimal value of $\\lambda$, and the corresponding model coefficients, using 3-fold CV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64670ca9-9dcb-4c45-bfa6-8f0bc73bb32c",
   "metadata": {},
   "source": [
    "*Note*: Remember, for lasso, you'll probably need to set that max_iter parameter. A value like 100,000 should be good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e5df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Plot how the weights change for lasso regression as lambda gets large here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7135db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Calculate the optimal value of lambda, and the corresponding model coefficients, using LOOCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc4d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Calculate the optimal value of lambda, and the corresponding model coefficients, using 3-fold CV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d9fbc-c967-439c-8fbe-8d04e41eb989",
   "metadata": {},
   "source": [
    "How do the predictors with non-zero coefficients compare with the ones found earlier in the assignment using backward stepwise selection?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
