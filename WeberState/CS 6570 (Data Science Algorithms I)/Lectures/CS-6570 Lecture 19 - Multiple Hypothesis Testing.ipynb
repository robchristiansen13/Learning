{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c91b5c0-316c-4813-99e7-00f95b0bfa8d",
   "metadata": {},
   "source": [
    "# CS-6570 Lecture 19 - Multiple Hypothesis Testing\n",
    "**Dylan Zwick**\n",
    "\n",
    "*Weber State University*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e3aa4-b896-48f5-b8d2-d34eeea0ecdc",
   "metadata": {},
   "source": [
    "In our last lecture we reviewed the basic procedures of hypothesis testing, and introduced some of the problems that can be encountered with multiple hypothesis testing. Today, we'll get into multiple hypothesis testing in greater depth, discussing some useful theoretical and practical techniques for limiting Type I error while not destroying the power (ability to avoid Type II error) of the test.\n",
    "\n",
    "First, let's review what multiple hypothesis testing is. Suppose you're a genomic researcher and you sequence the genomes of people with and without some particular medical condition, and then, for each of 20,000 genes, test whether sequence variants in that gene are associated with the medical condition of interest. This amounts to performing $m = 20,000$ hypothesis tests. The analysis is exploratory, not confirmatory, in nature, in the sense that you do not have any particular hypothesis in mind, and instead want to see whether there is modest evidence for the association between each gene and the disease, with a plan to further investigate any genes for which there is such evidence. It's OK to get some false positives here, but a $p$-value of, say, $.05$ probably isn't going to work well for you either, as you'd expect by random chance to have $1,000$ genes to investigate. You will get a lot of Type-I errors and wrongly rejected the null hypothesis.\n",
    "\n",
    "In our lecture today we'll discuss ways to balance Type I and Type II errors when doing exploratory testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4767c5-f762-4b9c-9bf1-eb49fb939bd0",
   "metadata": {},
   "source": [
    "But first, let's get some of the usual library imports out of the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6db4e20-1448-4509-95f5-d5de214c20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00403a83-8a8c-4e64-b626-9d35cef03585",
   "metadata": {},
   "source": [
    "**The Family-Wise Error Rate**\n",
    "\n",
    "In our last lecture, we discussed testing multiple hypotheses while controlling the probability of making at least one Type I error. Suppose we want to test $m$ null hypotheses, then we define the true positive, false positive, true negative, and false negative counts as follows:\n",
    "\n",
    "Columns are \"truth\" aka reality. Rows represent our actions (reject vs do not reject). Do not reject is more appropriate than \"accept\". \"Rejecting the null hypothesis\" is the good news for most tests. R is the total number of rejections. m-R is the number we do not reject.\n",
    "\n",
    "Type I error is when you discover something and you announce the world and later have to reject.\n",
    "Type II error is when you don't pick up on something and you should have. The \"Power\" of a criteria is how often you get miss it - like a frequency of Type II error: S / (W+S). The idea perfect test has V and W at 1 and no U or S.\n",
    "\n",
    "|  | $H_{0}$ is True | $H_{0}$ is False | Total |\n",
    "| :--- | :---: | :---: | :---: |\n",
    "| Reject $H_{0}$ | V | S | R |\n",
    "| Do Not Reject $H_{0}$ | U | W | m-R |\n",
    "| Total | $m_{0}$ | $m$-$m_{0}$ | $m$ |\n",
    "\n",
    "Recall from the last lecture that the Type I error rate is the probability of rejecting $H_{0}$ if $H_{0}$ is true, and the **family-wise error rate** (FWER) is the probability of making *at least one* Type I error. If we make the (rather strong) assumption that the $m$ tests are independent then if all $m$ null hypotheses are true and we reject the null hypothesis if it's $p$-value is less than $\\alpha$, then:\n",
    "\n",
    "\n",
    "$FWER(\\alpha) = 1 - (1-\\alpha)^{m}$\n",
    "\n",
    "If $m$ is reasonably large, then for even a small but not insignificant value of $\\alpha$ (like $.01$) this number will be very close to $1$. Below is a chart of the family-wise error rate as a function of $m$, the number of hypotheses tested, for three different values of $\\alpha$.\n",
    "\n",
    "<center>\n",
    "    <div>\n",
    "        <img src=\"FWER for Different alphas.png\" width=\"800\"/>\n",
    "    </div>\n",
    "</center>\n",
    "\n",
    "Certainly if $m = 20,000$ you're basically guaranteed a false positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c338e-9edf-4b8c-b243-6497eebc43d4",
   "metadata": {},
   "source": [
    "In class last time we learned the **Bonferroni method** for controlling the FWER, which states that if you want a FWER less than $\\alpha$, you only accept $p$-values less than $\\displaystyle \\frac{\\alpha}{m}$. If $m = 20,000$ then $\\alpha$ will be *very* small, and this is probably not OK, because there will likely be a great deal of Type II errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ba118-4a8c-47f5-a609-533c17aab919",
   "metadata": {},
   "source": [
    "A less restrictive variant of the Bonferroni method is **Holm's method** (a.k.a. Holm's step-down procedure). Holm's method is summarized in the algorithm description below. A proof that this method controls the FWER is not too bad, but is a bit beyond our scope for this class.\n",
    "\n",
    "**Holm's Method**\n",
    "\n",
    "1. Specify $\\alpha$ (0.05), the level at which to control the FWER.\n",
    "\n",
    "2. Compute $p$-values, $p_{1},\\ldots,p_{m}$, for the $m$ null hypotheses $H_{01},\\ldots,H_{0m}$. For every null hypothesis compute the p-values\n",
    "\n",
    "3. Order the $m$ $p$-values so that $p_{(1)} \\leq p_{(2)} \\leq \\cdots \\leq p_{(m)}$. << This is the interesting part\n",
    "\n",
    "4. Define $\\displaystyle L = min\\left\\{ j : p_{(j)} > \\frac{\\alpha}{m + 1 - j}\\right\\}$.\n",
    "\n",
    "5. Reject all null hypotheses $H_{0j}$ for which $p_{j} < p_{(L)}$.\n",
    "\n",
    "It's worth noting that the threshold we use to reject each null hypothesis, $p_{(L)}$ depends on the values of *all* $m$ of the $p$-values. Holm's method is uniformly more powerful than the Bonferroni method, and should always be preferred. You don't know your threshold until you've done some analysis on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c777ed-bef5-4306-af90-723e15026f7a",
   "metadata": {},
   "source": [
    "We'll investigate these methods using the [Fund](https://islp.readthedocs.io/en/latest/datasets/Fund.html) dataset provided for the book [An Introduction to Statistical Learning](https://www.statlearning.com/). It's a simulated data set containing the returns for 2,000 hedge fund managers. To load this dataset, we'll want to install the ISLP package, which we do below before we load the Fund dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d77ed234-3dcf-4639-a41f-ae5b2e3c1e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ISLP\n",
      "  Downloading ISLP-0.3.21-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy<1.25,>=1.7.1 in /opt/homebrew/lib/python3.11/site-packages (from ISLP) (1.24.4)\n",
      "Requirement already satisfied: scipy>=0.9 in /opt/homebrew/lib/python3.11/site-packages (from ISLP) (1.11.2)\n",
      "Collecting pandas<=1.9,>=0.20 (from ISLP)\n",
      "  Downloading pandas-1.5.3-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lxml (from ISLP)\n",
      "  Downloading lxml-4.9.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.2 in /opt/homebrew/lib/python3.11/site-packages (from ISLP) (1.3.0)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.11/site-packages (from ISLP) (1.3.2)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from ISLP) (0.14.0)\n",
      "Collecting lifelines (from ISLP)\n",
      "  Downloading lifelines-0.27.8-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pygam (from ISLP)\n",
      "  Downloading pygam-0.9.0-py3-none-any.whl (522 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m522.2/522.2 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/homebrew/lib/python3.11/site-packages (from ISLP) (2.0.1)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/homebrew/lib/python3.11/site-packages (from ISLP) (2.0.8)\n",
      "Requirement already satisfied: torchmetrics in /opt/homebrew/lib/python3.11/site-packages (from ISLP) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/robchristiansen/Library/Python/3.11/lib/python/site-packages (from pandas<=1.9,>=0.20->ISLP) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas<=1.9,>=0.20->ISLP) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn>=1.2->ISLP) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/homebrew/lib/python3.11/site-packages (from statsmodels>=0.13->ISLP) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/robchristiansen/Library/Python/3.11/lib/python/site-packages (from statsmodels>=0.13->ISLP) (23.1)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /opt/homebrew/lib/python3.11/site-packages (from lifelines->ISLP) (3.7.2)\n",
      "Collecting autograd>=1.5 (from lifelines->ISLP)\n",
      "  Downloading autograd-1.6.2-py3-none-any.whl.metadata (706 bytes)\n",
      "Collecting autograd-gamma>=0.3 (from lifelines->ISLP)\n",
      "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting formulaic>=0.2.2 (from lifelines->ISLP)\n",
      "  Downloading formulaic-0.6.6-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting progressbar2<5.0.0,>=4.2.0 (from pygam->ISLP)\n",
      "  Downloading progressbar2-4.2.0-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/homebrew/lib/python3.11/site-packages (from pytorch-lightning->ISLP) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/homebrew/lib/python3.11/site-packages (from pytorch-lightning->ISLP) (6.0.1)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in /opt/homebrew/lib/python3.11/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (2023.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/homebrew/lib/python3.11/site-packages (from pytorch-lightning->ISLP) (4.7.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from pytorch-lightning->ISLP) (0.9.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch->ISLP) (3.12.3)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch->ISLP) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch->ISLP) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch->ISLP) (3.1.2)\n",
      "Collecting future>=0.15.2 (from autograd>=1.5->lifelines->ISLP)\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting astor>=0.8 (from formulaic>=0.2.2->lifelines->ISLP)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines->ISLP)\n",
      "  Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting wrapt>=1.0 (from formulaic>=0.2.2->lifelines->ISLP)\n",
      "  Downloading wrapt-1.15.0-cp311-cp311-macosx_11_0_arm64.whl (36 kB)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/homebrew/lib/python3.11/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (3.8.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (3.0.9)\n",
      "Requirement already satisfied: six in /Users/robchristiansen/Library/Python/3.11/lib/python/site-packages (from patsy>=0.5.2->statsmodels>=0.13->ISLP) (1.16.0)\n",
      "Collecting python-utils>=3.0.0 (from progressbar2<5.0.0,>=4.2.0->pygam->ISLP)\n",
      "  Downloading python_utils-3.8.1-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch->ISLP) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch->ISLP) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning->ISLP) (2023.7.22)\n",
      "Downloading ISLP-0.3.21-py3-none-any.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lifelines-0.27.8-py3-none-any.whl (350 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.7/350.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-4.9.3-cp311-cp311-macosx_11_0_universal2.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading autograd-1.6.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading formulaic-0.6.6-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_utils-3.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Building wheels for collected packages: autograd-gamma, future\n",
      "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=189aa0310d17ae421ef0ce64c2f54c5b86e1bea176823450414f4c6e8d620c18\n",
      "  Stored in directory: /Users/robchristiansen/Library/Caches/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492024 sha256=9eb92d20fc422c9c94b167daf5a32741cca102cffc1864a1b3aed325a1d471fc\n",
      "  Stored in directory: /Users/robchristiansen/Library/Caches/pip/wheels/da/19/ca/9d8c44cd311a955509d7e13da3f0bea42400c469ef825b580b\n",
      "Successfully built autograd-gamma future\n",
      "Installing collected packages: wrapt, python-utils, lxml, interface-meta, future, astor, progressbar2, pandas, autograd, pygam, formulaic, autograd-gamma, lifelines, ISLP\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.1\n",
      "    Uninstalling pandas-2.1.1:\n",
      "      Successfully uninstalled pandas-2.1.1\n",
      "Successfully installed ISLP-0.3.21 astor-0.8.1 autograd-1.6.2 autograd-gamma-0.5.0 formulaic-0.6.6 future-0.18.3 interface-meta-1.3.0 lifelines-0.27.8 lxml-4.9.3 pandas-1.5.3 progressbar2-4.2.0 pygam-0.9.0 python-utils-3.8.1 wrapt-1.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ISLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f13cb3a-827f-473f-be20-13de6d61662e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manager1</th>\n",
       "      <th>Manager2</th>\n",
       "      <th>Manager3</th>\n",
       "      <th>Manager4</th>\n",
       "      <th>Manager5</th>\n",
       "      <th>Manager6</th>\n",
       "      <th>Manager7</th>\n",
       "      <th>Manager8</th>\n",
       "      <th>Manager9</th>\n",
       "      <th>Manager10</th>\n",
       "      <th>...</th>\n",
       "      <th>Manager1991</th>\n",
       "      <th>Manager1992</th>\n",
       "      <th>Manager1993</th>\n",
       "      <th>Manager1994</th>\n",
       "      <th>Manager1995</th>\n",
       "      <th>Manager1996</th>\n",
       "      <th>Manager1997</th>\n",
       "      <th>Manager1998</th>\n",
       "      <th>Manager1999</th>\n",
       "      <th>Manager2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.341992</td>\n",
       "      <td>-4.167469</td>\n",
       "      <td>9.389223</td>\n",
       "      <td>8.417220</td>\n",
       "      <td>0.997863</td>\n",
       "      <td>7.191473</td>\n",
       "      <td>-10.767592</td>\n",
       "      <td>4.072425</td>\n",
       "      <td>1.575264</td>\n",
       "      <td>-0.798505</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.948706</td>\n",
       "      <td>10.350706</td>\n",
       "      <td>-2.855337</td>\n",
       "      <td>-4.431786</td>\n",
       "      <td>0.739544</td>\n",
       "      <td>0.198044</td>\n",
       "      <td>1.752188</td>\n",
       "      <td>-1.534710</td>\n",
       "      <td>-3.359419</td>\n",
       "      <td>6.585654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.759627</td>\n",
       "      <td>12.525254</td>\n",
       "      <td>3.403366</td>\n",
       "      <td>0.143944</td>\n",
       "      <td>-7.222227</td>\n",
       "      <td>0.067747</td>\n",
       "      <td>-10.737053</td>\n",
       "      <td>-1.138185</td>\n",
       "      <td>-7.166604</td>\n",
       "      <td>4.778522</td>\n",
       "      <td>...</td>\n",
       "      <td>24.003150</td>\n",
       "      <td>-1.966606</td>\n",
       "      <td>-1.609109</td>\n",
       "      <td>1.405325</td>\n",
       "      <td>4.717175</td>\n",
       "      <td>1.540359</td>\n",
       "      <td>-12.218233</td>\n",
       "      <td>-0.073008</td>\n",
       "      <td>-8.547683</td>\n",
       "      <td>-2.382629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.970091</td>\n",
       "      <td>-2.581061</td>\n",
       "      <td>-0.824734</td>\n",
       "      <td>6.584604</td>\n",
       "      <td>17.050241</td>\n",
       "      <td>1.857130</td>\n",
       "      <td>3.196942</td>\n",
       "      <td>-7.981362</td>\n",
       "      <td>-1.214148</td>\n",
       "      <td>2.338250</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.926914</td>\n",
       "      <td>6.420147</td>\n",
       "      <td>8.946921</td>\n",
       "      <td>3.449013</td>\n",
       "      <td>1.009957</td>\n",
       "      <td>1.481369</td>\n",
       "      <td>14.203314</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>-5.105035</td>\n",
       "      <td>2.292429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.874630</td>\n",
       "      <td>7.981743</td>\n",
       "      <td>-4.026743</td>\n",
       "      <td>-4.731946</td>\n",
       "      <td>0.503276</td>\n",
       "      <td>0.740187</td>\n",
       "      <td>-28.969410</td>\n",
       "      <td>4.683751</td>\n",
       "      <td>-0.568840</td>\n",
       "      <td>-4.000547</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.112208</td>\n",
       "      <td>3.173581</td>\n",
       "      <td>-6.017109</td>\n",
       "      <td>-1.984873</td>\n",
       "      <td>1.022525</td>\n",
       "      <td>-2.261927</td>\n",
       "      <td>19.345970</td>\n",
       "      <td>-1.048299</td>\n",
       "      <td>-0.016154</td>\n",
       "      <td>1.196832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.019279</td>\n",
       "      <td>-5.370236</td>\n",
       "      <td>-4.854669</td>\n",
       "      <td>10.594432</td>\n",
       "      <td>-6.891574</td>\n",
       "      <td>9.877838</td>\n",
       "      <td>1.430033</td>\n",
       "      <td>9.840311</td>\n",
       "      <td>5.311455</td>\n",
       "      <td>18.365094</td>\n",
       "      <td>...</td>\n",
       "      <td>7.173653</td>\n",
       "      <td>-9.157211</td>\n",
       "      <td>7.643125</td>\n",
       "      <td>-1.022339</td>\n",
       "      <td>-1.325865</td>\n",
       "      <td>2.848785</td>\n",
       "      <td>-6.642081</td>\n",
       "      <td>2.488612</td>\n",
       "      <td>0.032060</td>\n",
       "      <td>-7.510032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Manager1   Manager2  Manager3   Manager4   Manager5  Manager6   Manager7   \n",
       "0  -3.341992  -4.167469  9.389223   8.417220   0.997863  7.191473 -10.767592  \\\n",
       "1   3.759627  12.525254  3.403366   0.143944  -7.222227  0.067747 -10.737053   \n",
       "2  12.970091  -2.581061 -0.824734   6.584604  17.050241  1.857130   3.196942   \n",
       "3  -4.874630   7.981743 -4.026743  -4.731946   0.503276  0.740187 -28.969410   \n",
       "4   2.019279  -5.370236 -4.854669  10.594432  -6.891574  9.877838   1.430033   \n",
       "\n",
       "   Manager8  Manager9  Manager10  ...  Manager1991  Manager1992  Manager1993   \n",
       "0  4.072425  1.575264  -0.798505  ...    -2.948706    10.350706    -2.855337  \\\n",
       "1 -1.138185 -7.166604   4.778522  ...    24.003150    -1.966606    -1.609109   \n",
       "2 -7.981362 -1.214148   2.338250  ...    -2.926914     6.420147     8.946921   \n",
       "3  4.683751 -0.568840  -4.000547  ...    -3.112208     3.173581    -6.017109   \n",
       "4  9.840311  5.311455  18.365094  ...     7.173653    -9.157211     7.643125   \n",
       "\n",
       "   Manager1994  Manager1995  Manager1996  Manager1997  Manager1998   \n",
       "0    -4.431786     0.739544     0.198044     1.752188    -1.534710  \\\n",
       "1     1.405325     4.717175     1.540359   -12.218233    -0.073008   \n",
       "2     3.449013     1.009957     1.481369    14.203314     0.005562   \n",
       "3    -1.984873     1.022525    -2.261927    19.345970    -1.048299   \n",
       "4    -1.022339    -1.325865     2.848785    -6.642081     2.488612   \n",
       "\n",
       "   Manager1999  Manager2000  \n",
       "0    -3.359419     6.585654  \n",
       "1    -8.547683    -2.382629  \n",
       "2    -5.105035     2.292429  \n",
       "3    -0.016154     1.196832  \n",
       "4     0.032060    -7.510032  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ISLP import load_data\n",
    "Fund = load_data('Fund')\n",
    "Fund.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a8f93a-5c41-4162-9f77-cca2b7c3e3dd",
   "metadata": {},
   "source": [
    "We can now constuct a one-sample $t$-test for each of the first five managers in this dataset, to test the null hypothesis that the $j$th fund manager's mean return equals zero, $H_{0,j}: \\mu_{j} = 0$. But first, we'll want to import the one-sample $t$-test function from the stats library in scipy. This is a two-sided T-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62625021-7bf1-4e9b-8d78-033ec05ac8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "737f5560-043c-4289-a7b4-34740335a53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00620236, 0.91827115, 0.01160098, 0.6005396 , 0.75578151])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund_mini = Fund.iloc[:,:5]\n",
    "fund_mini_pvals = np.empty(5) # This is a good pattern\n",
    "for i in range(5):\n",
    "    fund_mini_pvals[i] = ttest_1samp(fund_mini.iloc[:,i], 0).pvalue # We believe the average returns of fund managers is zero. \n",
    "fund_mini_pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311161f8-1f74-4e02-8709-e6d67a4d088b",
   "metadata": {},
   "source": [
    "The $p$-values are low for Managers One and Three, and high for the other three managers. However, we cannot simply reject $H_{0,1}$ and $H_{0,3}$, since this would fail to account for the multiple testing that we have performed. Instead, we will conduct Bonferroni’s method and Holm’s method to control the FWER.\n",
    "\n",
    "To do this, we use the [multipletests](https://www.statsmodels.org/dev/generated/statsmodels.stats.multitest.multipletests.html) function from the [statsmodels](https://www.statsmodels.org/dev/index.html) module (abbreviated to *mult_test*). Given the $p$-values, for methods like Holm and Bonferroni the function outputs *adjusted p-values*, which can be thought of as a new set of $p$-values that have been corrected for multiple $p$-values testing. If the adjusted $p$-value for a given hypothesis is less than or equal to $\\alpha$, then that hypothesis can be rejected while maintaining a FWER of no more than $\\alpha$. In other words, for such methods, the adjusted $p$-values resulting from the *multipletests* function can simply be compared to the desired FWER in order to determine whether or not to reject each hypothesis. We will later see that we can use the same function to control FDR as well.\n",
    "\n",
    "The *mult_test* function takes $p$-values and a method argument, as well as an optional $\\alpha$ argument. It returns the decisions (reject below) as well as the adjusted $p$-values (bonf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "323ff2de-f8af-45a5-a159-0363d352adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests as mult_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b06fae-7ea0-44ce-a742-f55f53fc2e58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mult_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/robchristiansen/Documents/Code/Learning/WeberState/CS 6570 (Data Science Algorithms I)/Lectures/CS-6570 Lecture 19 - Multiple Hypothesis Testing.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206570%20%28Data%20Science%20Algorithms%20I%29/Lectures/CS-6570%20Lecture%2019%20-%20Multiple%20Hypothesis%20Testing.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Means that there is less than a 5% chance that we reject the null hypothesis when we not have rejected it. alpha is the family wise error rate.\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206570%20%28Data%20Science%20Algorithms%20I%29/Lectures/CS-6570%20Lecture%2019%20-%20Multiple%20Hypothesis%20Testing.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m reject , bonf \u001b[39m=\u001b[39m mult_test(fund_mini_pvals , method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbonferroni\u001b[39m\u001b[39m\"\u001b[39m, alpha \u001b[39m=\u001b[39m \u001b[39m.05\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206570%20%28Data%20Science%20Algorithms%20I%29/Lectures/CS-6570%20Lecture%2019%20-%20Multiple%20Hypothesis%20Testing.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m reject\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mult_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Means that there is less than a 5% chance that we reject the null hypothesis when we not have rejected it. alpha is the family wise error rate.\n",
    "reject , bonf = mult_test(fund_mini_pvals , method = \"bonferroni\", alpha = .05)[:2]\n",
    "\n",
    "reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36822ff5-cf19-4672-b409-b7ac7481fbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03101178, 1.        , 0.05800491, 1.        , 1.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gives the adjusted p-values \n",
    "bonf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877e260-ba1d-4615-8b1d-af9ee73f5bb6",
   "metadata": {},
   "source": [
    "These are simply the *fund_mini* $p$-values multiplied by $5$ and truncated to be less than or equal to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d06a5d-cef7-4c95-8aaf-58690ab9c43d",
   "metadata": {},
   "source": [
    "So, using the Bonferroni method we were able to reject one null hypothesis, for the first fund manager. Fund manager 3 was awful close."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6eada-acf2-41b4-8242-9396449aca8f",
   "metadata": {},
   "source": [
    "On the other hand, using Holm's method, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79a8100e-674c-473e-9789-710b5e02d9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True, False,  True, False, False]),\n",
       " array([0.03101178, 1.        , 0.04640393, 1.        , 1.        ]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult_test(fund_mini_pvals , method = \"holm\", alpha = .05)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5fa00e-f8c2-44fb-90f0-f66ba09ad031",
   "metadata": {},
   "source": [
    "So, we reject the null hypothesis both for manager 1 and manager 3. Holm's method has more *power* than Bonferroni's. Holm's method is likely to have Type II error (accepted when should have rejected (and published a celebratory article))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282cd05b-d485-4c57-83d3-fed81af744a0",
   "metadata": {},
   "source": [
    "Using both Holm's method and the Bonferroni method, rejecting the null hypothesis becomes more difficult as the number of hypotheses, $m$, increases. This makes sense. The goal of the FWER is to prevent *any* Type I error. If there are many hypotheses, then to prevent any Type I error, you'll end up accepting the null hypothesis almost every time. This will significantly decrease the power of your method, and you'll likely miss cases where you should reject the null hypothesis. In practice, when $m$ is large, we may be willing to tolerate a few false positives, in the interest of making more discoveries. This is the motivation behind the **false discovery rate**. So, an FDR (usually denoted with $q$) of 20% would correspond with rejecting as many null hypotheses as possible while guaranteeing no more than 20% of those rejected are, on average, false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40fa92d-13be-4e97-8957-17c8198614bb",
   "metadata": {},
   "source": [
    "**The False Discovery Rate**\n",
    "\n",
    "When $m$ is large, then trying to reject *any* Type I error is just too stringent. Instead , we might try to make sure the ratio of false positives (V) to total positives (V + S = R) is sufficiently low, so that most of the rejected null hypotheses are not false positives. The ratio $\\displaystyle \\frac{V}{R}$ is knows as the *false discovery proportion* (FDP). V is the number of times you incorrectly reject the null hypothesis. R is the total number of rejections. Now, of course, in practice we don't know which positives are false and which are not. If we did, we wouldn't be doing experiments. So, we can't work with the FDP directly, and instead focus on its expectation $E(FDP)$ which is the *false discovery rate* (FDR). Note there is no standard, accepted threshold for FDR control. Instead, the choice of FDR threshold is typically context-dependent.\n",
    "\n",
    "So, for a set value of $q$, what is the corresponding rejection criteria on the $p$-value? Well, it turns out there's a very simple procedure for calculating it, known as the *Benjamini-Hochberg* procedure.\n",
    "\n",
    "1. Specify $q$, the level at which to control the FDR.\n",
    "\n",
    "2. Computer $p$-values $p_{1},\\ldots,p_{m}$, for the $m$ null hypotheses $H_{01},\\ldots,H_{0m}$.\n",
    "\n",
    "3. Order the $m$ $p$-values so that $p_{(1)} \\leq p_{(2)} \\leq \\cdots \\leq p_{(m)}$.\n",
    "\n",
    "4. Define $\\displaystyle L = max\\left\\{j : p_{(j)} \\leq \\frac{qj}{m}\\right\\}$.\n",
    "\n",
    "5. Reject all null hypotheses $H_{0}$ for which $p_{j} \\leq p_{(L)}$.\n",
    "\n",
    "The proof of this is well beyond the scope of this class. Also, note the rejection threshold depends upon the $p$-values of our data, and so (unlike with Bonferroni) we can't know what it will be before the data is analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be968e4-d00c-4d97-8d01-f0752d1d36ec",
   "metadata": {},
   "source": [
    "Going back to our *Fund* dataset, we can perform hypothesis tests for all 2,000 fund managers. We perform a one-sample $t$-test of $H_{0,j} : \\mu_{j} = 0$, which states that the $j$th fund manager's mean return is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97c72094-1548-43d7-bee0-cfc8107c5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_pvalues = np.empty(2000)\n",
    "for i, manager in enumerate(Fund.columns):\n",
    "    fund_pvalues[i] = ttest_1samp(Fund[manager], 0).pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656125b-2f41-4d30-8667-f1c2129956f1",
   "metadata": {},
   "source": [
    "There are far too many managers to consider trying to control the FWER. Instead, we  focus on controlling the FDR: that is, the expected fraction of rejected null hypotheses that are actually false positives. The *multi-test* function we used earlier can be used to carry out the Benjaminni-Hochberg procedure described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a867a40-bd3c-424d-81b9-5780cb8c4182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08988921, 0.991491  , 0.12211561, 0.92342997, 0.95603587,\n",
       "       0.07513802, 0.0767015 , 0.07513802, 0.07513802, 0.07513802])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund_qvalues = mult_test(fund_pvalues , method = \"fdr_bh\")[1]\n",
    "fund_qvalues [:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8337a1f1-e971-43b1-abe2-953d3649fc31",
   "metadata": {},
   "source": [
    "The $q$-values output can be interpreted as the smallest FDR threshold at which we would reject a particular null hypothesis. For example, a $q$-value of $0.1$ indicates that we can reject the corresponding null hypothesis at an FDR of 10% or greater, but that we cannot reject the null hypothesis at an FDR below 10%. If we control the FDR at 10%, how many fund managers can we reject?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed33cc1a-acb5-4338-9577-a9584e29f4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fund_qvalues <= 0.1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfc4131-4732-400f-853c-b3923237ca64",
   "metadata": {},
   "source": [
    "146 fund managers could be considered. On the other hand, if we'd used Bonferroni's method to control the FWER at level $\\alpha = .1$, we would have failed to reject any null hypotheses! Bonferroni's method is very WEAK (you'll get a lot of Type II errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3a55954-2d97-47dd-8f34-1ad527544d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fund_pvalues <= 0.1 / 2000).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dcfc86-d51a-4bad-9df5-5344338db0da",
   "metadata": {},
   "source": [
    "**A Re-Sampling Approach to $p$-Values and False Discovery Rates**\n",
    "\n",
    "Let's say X represents a population with a medical condition and Y represents the population without a medical condition. We'll say the average value of X = the average of Y (null hypothesis). Furthermore, we'll say the populations are exactly the same. If the populations are indeed the same, then we should be able to swap samples between X and Y (permute the observations). We're going to take our observations and we're going to combine them into a new set of observations and then we randomly permute the observations into new X(1 star) and Y (1 star).x_{1}^*. Then we can get a T-statistic of how apart the means are.  \n",
    "\n",
    "So far, we've assumed we're testing a particular null hypothesis $H_{0}$ using a test statistic $T$, which has some assumed distribution under $H_{0}$. However, if our null hypothesis $H_{0}$ or test statistic $T$ is somewhat unusual, then it may be the case that no theoretical null distribution is available. Alternatively, even if a theoretical null distribution exists, then we may be wary of relying upon it, perhaps because some assumption that is required for it to hold is violated. For example, maybe the sample size is small. We can still perform inference in this setting, exploiting the availability of fast computers.\n",
    "\n",
    "Recall from our last lecture that that if our null hypothesis is the mean of a random variable $X$ equals the mean of a random variable $Y$, then given $n_{X}$ and $n_{Y}$ independent observations of $X$ and $Y$ respectively, the two-sample t-statistic is if the form:\n",
    "\n",
    "$\\displaystyle T = \\frac{\\hat{\\mu_{X}} - \\hat{\\mu_{Y}}}{s\\sqrt{\\frac{1}{n_{X}} + \\frac{1}{n_{Y}}}}$\n",
    "\n",
    "where $\\hat{\\mu_{X}}$ and $\\hat{\\mu_{Y}}$ are the sample means for the test and control groups respectively, and\n",
    "\n",
    "$\\displaystyle s = \\sqrt{\\frac{(n_{X}-1)s_{Y}^{2} + (n_{Y}-1)s_{Y}^{2}}{n_{X} + n_{Y} - 2}}$\n",
    "\n",
    "is an estimator of the pooled standard deviation of the two samples. Here, $\\displaystyle s_{X}^{2} = \\frac{\\sum_{i = 1}^{n_{X}}(x_{i}^{2}-\\mu_{X}^{2})}{n_{X}-1}$ and $\\displaystyle s_{Y}^{2} = \\frac{\\sum_{i = 1}^{n_{Y}}(y_{i}^{2}-\\mu_{Y}^{2})}{n_{Y}-1}$ are unbiased estimators of the variance of the blood pressure in the treatment and control groups, respectively. A large (absolute) value of $T$ provides evidence against $H_{0}: \\mu_{X} = \\mu_{Y}$, and hence evidence in support of $H_{a}: \\mu_{X} \\neq \\mu_{Y}$.\n",
    "\n",
    "If $n_{X}$ and $n_{Y}$ are large, then $T$ is approximately a normal distribution with mean 0 and variance 1. However, if, say, $n_{X}$ and $n_{Y}$ are small, then in the absence of a strong assumption about the distributions of $X$ and $Y$, we do not know the theoretical null distribution of $T$. In this case, we can approximate the null distribution of $T$ using a *re-sampling* approach, or more specifically, a *permutation* approach.\n",
    "\n",
    "To see this, we conduct a thought experiment. If $H_{0}$ holds, so that $\\mu_{X} = \\mu_{Y}$, and we make the *stronger* assumption that the distributions of $X$ and $Y$ are the same, then the distribution of $T$ is invariant under swapping observations of $X$ with observations of $Y$. That is, if we randomly swap some of the observations in $X$ with the observations in $Y$, then the test statistic $T$ computed based on this swapped data has the same distribution as $T$ based on the original data. Please note this is true only if $H_{0}$ holds and the distributions of $X$ and $Y$ are the same.\n",
    "\n",
    "This suggests the following approach. To approximate the null distribution of $T$, we randomly permute the $n_{X} + n_{Y}$ observations $B$ times, for some large value of $B$ like $10,000$, and each time we compute the $T$ statistic. We can let $T^{*1}, \\ldots, T^{*B}$ denote the values of these $T$ statistics on the permuted data. Using these, to compute a $p$-value for $T$, we simply compute:\n",
    "\n",
    "$p$-value $\\displaystyle = \\frac{\\sum_{b = 1}^{B} 1_{(|T^{*b}| \\geq |T|)}}{B}$\n",
    "\n",
    "We can define this procedure algorithmically as:\n",
    "\n",
    "1. Compute $T$ on the original data $x_{1},x_{2},\\ldots,x_{n_{X}}$, and $y_{1},y_{2},\\ldots,y_{n_{Y}}$.\n",
    "\n",
    "2. For $b = 1,2,\\ldots,B$, where $B$ is a large number (like $10,000$):\n",
    "\n",
    "    (a) Permute the $n_{X}$ and $n_{Y}$ observations at random. Call the first $n_{X}$ permuted observations $x_{1}^{*},x_{2}^{*},\\ldots,x_{n_{X}}^{*}$, and call the remaining observations $y_{1}^{*},y_{2}^{*},\\ldots,y_{n_{Y}}^{*}$.\n",
    "    \n",
    "    (b) Compute $T$ on the permuted data $x_{1}^{*},x_{2}^{*},\\ldots,x_{n_{X}}^{*}$, and $y_{1}^{*},y_{2}^{*},\\ldots,y_{n_{Y}}^{*}$, and call the result $T^{*b}$.\n",
    "    \n",
    "3. The $p$-value is given by $\\displaystyle \\frac{\\sum_{b = 1}^{B} 1_{(|T^{*b}| \\geq |T|)}}{B}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a98a647-b578-4b6a-b152-4982f9c5c9f3",
   "metadata": {},
   "source": [
    "We can also apply this approach to the False Discovery Rate (FDR) calculation. Suppose we wish to control the FDR for $m$ null hypotheses, $H_{01},\\ldots,H_{0m}$, where either no theoretical null distribution is available, or we prefer to avoid the use of a theoretical null distribution. We can make use of the two-sample $t$-statistic for each hypothesis, leading to the test statistics $T_{1},\\ldots,T_{m}$. We could simply compute the $p$-value for each of the $m$ hypotheses using the re-sampling method above, and then apply the Benjamini-Hochberg procedure to these $p$-values. However, we can do this in an even more direct way without calculating $p$-values!\n",
    "\n",
    "Recall the FDR is defined as $\\displaystyle E\\left(\\frac{V}{R}\\right)$ where $V$ is the count of false-positives, and $R$ is the count of true-positives. To estimate the FDR via re-sampling, we make the assumption that $\\displaystyle E\\left(\\frac{V}{R}\\right) \\approx \\frac{E(V)}{R}$. If we reject any null hypothesis for which the test statistic exceeds some number $c$ is absolute value, then calculating $R$ is straightforward, $\\displaystyle R = \\sum_{i = 1}^{m} 1_{(|T_{j}| \\geq c)}$. However, estimating $V$ is difficult. One way to do it is with a re-sampling approach.\n",
    "\n",
    "For each of the null hypotheses $H_{01},\\ldots,H_{0m}$, we can estimate $E(V)$ as follows. Let $x_{1}^{(j)},\\ldots,x_{n_{X}}^{(j)}$ and $y_{1}^{(j)},\\ldots,y_{n_{Y}}^{(j)}$ be the data associated with the $j$th null hypothesis, with $j = 1,\\ldots,m$. We permute the $n_{X} + n_{Y}$ observations at random, and then permute the $t$-statistic on the permuted data. For this permuted data, we know all the null hypotheses hold, and so the number of permuted $t$-statistics that exceed the threshold $c$ in absolute value provides an estimate for $E(V)$. We can improve this estimate by repeating the permutation process $B$ times, for some large number $B$, and averaging the results. This procedure is described in the algorithm below:\n",
    "\n",
    "1. Select a threshold $c$, where $c > 0$.\n",
    "\n",
    "2. For $j = 1,\\ldots,m:\n",
    "\n",
    "    (a) Compute $T^{(j)}$, the two-sample $t$-statistic for the null hypothesis $H_{0j}$ on the basis of the original data $x_{1}^{(j)},\\ldots,x_{n_{X}}^{(j)}$ and $y_{1}^{(j)},\\ldots,y_{n_{Y}}^{(j)}$.\n",
    "    \n",
    "    (b) For $b = 1,\\ldots,B$, where $B$ is a large number (like $10,000$)\n",
    "    \n",
    "    - Permute the $n_{X}+ n_{Y}$ observations at random. Call the first $n_{X}$ observations $x_{1}^{*(j)},x_{2}^{*(j)},\\ldots,x_{n_{X}}^{*(j)}$, and call the remaining observations $y_{1}^{*(j)},y_{2}^{*(j)},\\ldots,y_{n_{Y}}^{*(j)}$.\n",
    "    \n",
    "    - Compute the T statistic on the permuted data $x_{1}^{*(j)},x_{2}^{*(j)},\\ldots,x_{n_{X}}^{*(j)}$, and $y_{1}^{*(j)},y_{2}^{*(j)},\\ldots,y_{n_{Y}}^{*(j)}$, and call the result $T^{(j),*b}$.\n",
    "    \n",
    "3. Compute $\\displaystyle R = \\sum_{i = 1}^{m} 1_{(|T_{j}| \\geq c)}$\n",
    "\n",
    "4. Compute $\\displaystyle \\hat{V} = \\frac{\\sum_{b = 1}^{B} \\sum_{j = 1}^{m} 1_{(|T^{(j),*b}| \\geq c)}}{B}$\n",
    "\n",
    "5. The estimated FDR associated with the threshold $c$ is $\\displaystyle \\frac{\\hat{V}}{R}$\n",
    "\n",
    "In general, there are two settings in which a re-sampling approach is particularly useful:\n",
    "\n",
    "1. Perhaps no theoretical null distribution is available. This may be the case if you are testing an unusual null hypothesis $H_{0}$, or using an unusual test statistic $T$.\n",
    "\n",
    "2. Perhaps a theoretical null distribution *is* available, but the assumptions required for its validity do not hold. **For example, you don't have a large number of observations.** \n",
    "\n",
    "In many real-world settings, re-sampling is a powerful tool for hypothesis testing when no out-of-the-box hypothesis tests are available, or key assumptions are violated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
