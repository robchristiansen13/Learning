{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8f3375",
   "metadata": {},
   "source": [
    "Today we're going to learn about a classifier that has no business being as good as it is, given how simple it is - the naive Bayes classifier, which is a powerful and robust tool for classifying categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a43fef",
   "metadata": {},
   "source": [
    "**Naive Bayes**\n",
    "\n",
    "The naive Bayes algorithm begins with Bayes law, which is a simple deduction from the basic formula for conditional probability:\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(X|Y) = \\frac{P(X \\cap Y)}{P(Y)}$\n",
    "</center>\n",
    "\n",
    "If we turn this formula aronud, we get:\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(Y|X) = \\frac{P(X \\cap Y)}{P(X)}$,\n",
    "</center>\n",
    "\n",
    "from which we get:\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(Y|X) = \\frac{P(X|Y)P(Y)}{P(X)}$.\n",
    "</center>\n",
    "\n",
    "This last formula is known as Bayes' theroem, and it relates how likely an event $Y$ is (called the prior probability), to how likely it is given additional inforamation $X$ (the posterior probability). Note the term $P(X|Y)$ is called the *likelihood*, and the term $P(X)$ is called the *marginal*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d9d2e",
   "metadata": {},
   "source": [
    "In their book \"Thinking Fast and Slow\" Kahneman and Tversky present the following question: suppose you pick a person at random from the population of the United States, and are given the following description of the person \"Steve is very shy and withdrawn, invariably helpful but with little interest in people or in the world of reality. A meek and tidy soul, he has a need for order and structure, and a passion for detail.” Is Steve more likely to be a librarian or a farmer?\n",
    "\n",
    "According to Kahneman, most people think Steve is more likely to be a librarian, focusing on an occupational stereotype while ignoring a much more important fact - there are far more farmers than librarians."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c4f2c",
   "metadata": {},
   "source": [
    "Let's see how Bayes' theorem relates to this question. Suppose in a population of 10,000 there are 200 farmers and 10 librarians, and suppose that 40% of librarians, 5% of farmers, and 3% of the general population meet the above description. In that case, what is the probability that a randomly chosen person who meets this description is a librarian? Well, we know the probabilities of a random person from the population being a librarian, a farmer, and fitting this description are, respectively:\n",
    "\n",
    "<center>\n",
    "    $P(L) = .1\\%$,\n",
    "    $P(F) = 2\\%$,\n",
    "    $P(D) = 3\\%$.\n",
    "</center>\n",
    "\n",
    "So, according to Bayes' theorem, the conditional probability of the randomly selected person being a librarian given that description is:\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(L|D) = \\frac{P(D|L)P(L)}{P(D)} = \\frac{.4 \\times .001}{.03} = .013$,\n",
    "</center>\n",
    "\n",
    "while the probability of the randomly selected person being a farmer given that  description is:\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(F|D) = \\frac{P(D|F)P(F)}{P(D)} = \\frac{.05 \\times .02}{.03} = .033$.\n",
    "</center>\n",
    "\n",
    "So, the randomly selected person is over twice as likely to be a farmer, even though their description applies to a much higher percentage of librarians than farmers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183156d1",
   "metadata": {},
   "source": [
    "Alright, so what does this have to do with categorical prediction? Well, suppose we're trying to predict the category of an observation from a set, where the possible categories are $y_{1},y_{2},\\ldots,y_{k}$, and we're given as our input $X = (x_{1},x_{2},\\ldots,x_{n})$. In that case, Bayes' theorem tells us that the respective probabilities of the different outcomes are:\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(y_{1}|x_{1},x_{2},\\ldots,x_{n}) = \\frac{P(x_{1},x_{2},\\ldots,x_{n}|y_{1})P(y_{1})}{P(x_{1},x_{2},\\ldots,x_{n})} = \\frac{P(X|y_{1})P(y_{1})}{P(X)}$,\n",
    "</center>\n",
    "&nbsp;\n",
    "<center>    \n",
    "    $\\displaystyle P(y_{2}|x_{1},x_{2},\\ldots,x_{n}) = \\frac{P(x_{1},x_{2},\\ldots,x_{n}|y_{2})P(y_{2})}{P(x_{1},x_{2},\\ldots,x_{n})} = \\frac{P(X|y_{2})P(y_{2})}{P(X)}$,\n",
    "</center>\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\vdots$\n",
    "</center>    \n",
    "    &nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(y_{k}|x_{1},x_{2},\\ldots,x_{n}) = \\frac{P(x_{1},x_{2},\\ldots,x_{n}|y_{k})P(y_{k})}{P(x_{1},x_{2},\\ldots,x_{n})} = \\frac{P(X|y_{k})P(y_{k})}{P(X)}$.\n",
    "</center>\n",
    "\n",
    "So, in order to pick the most likely outcome, we just need to calculate the above probabilities, and determine which is more likely. How do we do this? Well, we just count their frequencies!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a17dd",
   "metadata": {},
   "source": [
    "This might seem like an overly simplistic model, but the amazing thing is that, with enough data, this is literally the best possible model there is. I'm not kidding. This can't be beat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cad4b4f",
   "metadata": {},
   "source": [
    "OK, well then why don't we just always use this model? Because we very, very rarely have enough data. That is to say, for a given set of inputs $(x_{1},x_{2},\\ldots,x_{n})$ we rarely have much, if any, training data, and if we have no training data for exactly that specific set of inputs, then the model above completely breaks down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8600136c",
   "metadata": {},
   "source": [
    "How do we fix this problem? We need to make some assumptions. Now, these assumptions are rarely if ever completely true, but they can be close enough to true in order to be useful. The assumption we make in the naive Bayes model is that the probabilities of observing each of our input variables are conditionally independent:\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $P(x_{1},x_{2},\\ldots,x_{n}|y_{i}) = P(x_{1}|y_{i})P(x_{2}|y_{i}) \\cdots P(x_{n}|y_{i})$.\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6961d3",
   "metadata": {},
   "source": [
    "What do we mean by conditionally independent? Well, suppose we had two variables $X$ and $Y$, where $X$ represents going to the beach on a given Saturday, and $Y$ represents getting sunburned on that same Saturday. It would make sense to say that the probabilities of these events are not independent - if you go to the beach you're likely to get sunburned. However, it could be that these events *are* independent given knowledge of a third variable $H$ - whether it's hot outside. It could be that you're equally likely to get a sunburn on a hot day whether or not you go to the beach, but you're also more likely to go to the beach on a hot day. Mathematically, we'd write this as:\n",
    "\n",
    "<center>\n",
    "    $P(X \\cap Y) > P(X)P(Y)$,\n",
    "</center>\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "but\n",
    "</center>\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $P(X \\cap Y | H) = P(X|H)P(Y|H)$.\n",
    "</center>\n",
    "\n",
    "This would mean that $X$ and $Y$ are conditionally independent given $H$. This conditional independence is the assumption we make in the naive Bayes model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df94c36b",
   "metadata": {},
   "source": [
    "One final thing to note is that if the input value $x_{i}$ never shows up with an associated output value $y_{j}$, then we'll have $P(x_{i}|y_{j}) = 0$, and so $P(x_{1},x_{2},\\ldots,x_{i},\\ldots,x_{n}|y_{j}) = P(x_{1}|y_{j})P(x_{2}|y_{j}) \\cdots P(x_{n}|y_{j}) = 0$, regardless of the other conditional probabilities. This can cause problems in our model, so the way we deal with this is to introduce a smoothing parameter.\n",
    "\n",
    "One commonly used, and one we will use in our spam filter below, is called \"Laplace smoothing\", and it defines:\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(x_{i}|y) = \\frac{N_{x_{i}|y} + \\alpha}{N_{y} + \\alpha n}$\n",
    "</center>\n",
    "\n",
    "Here, $n$ in the number of features in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3041141",
   "metadata": {},
   "source": [
    "OK, let's see how we could use the naive Bayes model to build a spam filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2eeb84",
   "metadata": {},
   "source": [
    "To build our spam filter, we'll use a dataset of 5,572 SMS messages. Tiago A. Almeida and José María Gómez Hidalgo put together the dataset, you can download it from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9be4bd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sms_spam = pd.read_csv('SMSSpamCollection', sep='\\t',\n",
    "header=None, names=['Label', 'SMS'])\n",
    "\n",
    "print(sms_spam.shape)\n",
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3231bb",
   "metadata": {},
   "source": [
    "We see that about 87% of the messages are ham (non-spam), and the remaining 13% are spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb3147d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf58d42a",
   "metadata": {},
   "source": [
    "We're going to split our dataset into a training set and a testing set, this time without using the train_test_split function, to see what's going on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69561d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomize the dataset\n",
    "data_randomized = sms_spam.sample(frac=1, random_state=42)\n",
    "\n",
    "# Calculate index for split\n",
    "training_test_index = round(len(data_randomized) * 0.8)\n",
    "\n",
    "# Split into training and test sets\n",
    "training_set = data_randomized[:training_test_index].reset_index(drop=True)\n",
    "test_set = data_randomized[training_test_index:].reset_index(drop=True)\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70dd5d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.861759\n",
       "spam    0.138241\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Label'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef222e40",
   "metadata": {},
   "source": [
    "Now we're going to remove the punctuation from our messages, and convert everything to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55cfa066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>squeeeeeze   this is christmas hug   if u lik ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>and also i ve sorta blown him off a couple tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>mmm thats better now i got a roast down me  i ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  squeeeeeze   this is christmas hug   if u lik ...\n",
       "1   ham  and also i ve sorta blown him off a couple tim...\n",
       "2   ham  mmm thats better now i got a roast down me  i ..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After cleaning\n",
    "training_set['SMS'] = training_set['SMS'].str.replace(\n",
    "   '\\W', ' ') # Removes punctuation\n",
    "training_set['SMS'] = training_set['SMS'].str.lower()\n",
    "training_set.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c3c8a6",
   "metadata": {},
   "source": [
    "Next, we create the vocabulary, which is the set of words in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "734af358",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "for sms in training_set['SMS']:\n",
    "   for word in sms:\n",
    "      vocabulary.append(word)\n",
    "\n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02e7552f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7816"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84527e50",
   "metadata": {},
   "source": [
    "Next, we create a dictionary (a key / value pair data object) that maps each word in the vocabulary to a count of the number of times it appears in each message. Note that most will be 0. We then convert it to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c7cdd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "   for word in sms:\n",
    "      word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4075bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>downstem</th>\n",
       "      <th>pounds</th>\n",
       "      <th>addicted</th>\n",
       "      <th>reach</th>\n",
       "      <th>lautech</th>\n",
       "      <th>situation</th>\n",
       "      <th>conform</th>\n",
       "      <th>heron</th>\n",
       "      <th>malaria</th>\n",
       "      <th>ac</th>\n",
       "      <th>...</th>\n",
       "      <th>dane</th>\n",
       "      <th>had</th>\n",
       "      <th>docks</th>\n",
       "      <th>babies</th>\n",
       "      <th>balloon</th>\n",
       "      <th>ibn</th>\n",
       "      <th>kaypoh</th>\n",
       "      <th>clover</th>\n",
       "      <th>wan</th>\n",
       "      <th>compensation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7816 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   downstem  pounds  addicted  reach  lautech  situation  conform  heron  \\\n",
       "0         0       0         0      0        0          0        0      0   \n",
       "1         0       0         0      0        0          0        0      0   \n",
       "2         0       0         0      0        0          0        0      0   \n",
       "3         0       0         0      0        0          0        0      0   \n",
       "4         0       0         0      0        0          0        0      0   \n",
       "\n",
       "   malaria  ac  ...  dane  had  docks  babies  balloon  ibn  kaypoh  clover  \\\n",
       "0        0   0  ...     0    0      0       0        0    0       0       0   \n",
       "1        0   0  ...     0    0      0       0        0    0       0       0   \n",
       "2        0   0  ...     0    1      0       0        0    0       0       0   \n",
       "3        0   0  ...     0    0      0       0        0    0       0       0   \n",
       "4        0   0  ...     0    0      0       0        0    0       0       0   \n",
       "\n",
       "   wan  compensation  \n",
       "0    0             0  \n",
       "1    0             0  \n",
       "2    0             0  \n",
       "3    0             0  \n",
       "4    0             0  \n",
       "\n",
       "[5 rows x 7816 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733b59a6",
   "metadata": {},
   "source": [
    "We don't have the label column in this dataset, so we can add it by concatenating the datframe we just built with the dataframe containing our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c852ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>downstem</th>\n",
       "      <th>pounds</th>\n",
       "      <th>addicted</th>\n",
       "      <th>reach</th>\n",
       "      <th>lautech</th>\n",
       "      <th>situation</th>\n",
       "      <th>conform</th>\n",
       "      <th>heron</th>\n",
       "      <th>...</th>\n",
       "      <th>dane</th>\n",
       "      <th>had</th>\n",
       "      <th>docks</th>\n",
       "      <th>babies</th>\n",
       "      <th>balloon</th>\n",
       "      <th>ibn</th>\n",
       "      <th>kaypoh</th>\n",
       "      <th>clover</th>\n",
       "      <th>wan</th>\n",
       "      <th>compensation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[squeeeeeze, this, is, christmas, hug, if, u, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[and, also, i, ve, sorta, blown, him, off, a, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[mmm, thats, better, now, i, got, a, roast, do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[mm, have, some, kanji, dont, eat, anything, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[so, there, s, a, ring, that, comes, with, the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7818 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  downstem  pounds  \\\n",
       "0   ham  [squeeeeeze, this, is, christmas, hug, if, u, ...         0       0   \n",
       "1   ham  [and, also, i, ve, sorta, blown, him, off, a, ...         0       0   \n",
       "2   ham  [mmm, thats, better, now, i, got, a, roast, do...         0       0   \n",
       "3   ham  [mm, have, some, kanji, dont, eat, anything, h...         0       0   \n",
       "4   ham  [so, there, s, a, ring, that, comes, with, the...         0       0   \n",
       "\n",
       "   addicted  reach  lautech  situation  conform  heron  ...  dane  had  docks  \\\n",
       "0         0      0        0          0        0      0  ...     0    0      0   \n",
       "1         0      0        0          0        0      0  ...     0    0      0   \n",
       "2         0      0        0          0        0      0  ...     0    1      0   \n",
       "3         0      0        0          0        0      0  ...     0    0      0   \n",
       "4         0      0        0          0        0      0  ...     0    0      0   \n",
       "\n",
       "   babies  balloon  ibn  kaypoh  clover  wan  compensation  \n",
       "0       0        0    0       0       0    0             0  \n",
       "1       0        0    0       0       0    0             0  \n",
       "2       0        0    0       0       0    0             0  \n",
       "3       0        0    0       0       0    0             0  \n",
       "4       0        0    0       0       0    0             0  \n",
       "\n",
       "[5 rows x 7818 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b248c9",
   "metadata": {},
   "source": [
    "Now that we're done cleaning and preparing our data, we can code the spam filter. The naive Bayes algorithm will need, for a given set of words, to calculate:\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(Spam|w_{1},w_{2},\\ldots,w_{n}) \\propto P(Spam) \\cdot \\prod_{i = 1}^{n}P(w_{i}|Spam)$\n",
    "</center>\n",
    "\n",
    "and\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(Ham|w_{1},w_{2},\\ldots,w_{n}) \\propto P(Ham) \\cdot \\prod_{i = 1}^{n}P(w_{i}|Ham)$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2267df0",
   "metadata": {},
   "source": [
    "To calculate $P(w_{i}|Spam)$ and $P(w_{i}|Ham)$ inside the formulas above, we'll need to use these equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07abe4",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(w_{i}|Spam) = \\frac{N_{w_{i}|Spam} + \\alpha}{N_{spam} + \\alpha N_{Vocabulary}}$\n",
    "</center>\n",
    "\n",
    "and\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(w_{i}|Ham) = \\frac{N_{w_{i}|Ham} + \\alpha}{N_{Ham} + \\alpha N_{Vocabulary}}$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24fb3a3",
   "metadata": {},
   "source": [
    "Some of the terms in the four equations above will have the same value for every new message. We can calculate the value of these terms once and avoid doing the computations again when a new messages comes in. As a start, let's first calculate:\n",
    "\n",
    "* $P(Spam)$ and $P(Ham)$\n",
    "* $N_{Spam}$, $N_{Ham}$, and $N_{Vocabulary}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f54919a",
   "metadata": {},
   "source": [
    "It's important to note:\n",
    "\n",
    "* $N_{Spam}$ is equal to the number of words in all the spam messages — it's not equal to the number of spam messages, and it's not equal to the total number of unique words in spam messages.\n",
    "* $N_{Ham}$ is equal to the number of words in all the non-spam messages — it's not equal to the number of non-spam messages, and it's not equal to the total number of unique words in non-spam messages.\n",
    "\n",
    "We'll also use Laplace smoothing and set $\\alpha = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2236fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating spam and ham messages first\n",
    "spam_messages = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)\n",
    "\n",
    "# N_Spam\n",
    "n_words_per_spam_message = spam_messages['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# N_Ham\n",
    "n_words_per_ham_message = ham_messages['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3cda06",
   "metadata": {},
   "source": [
    "Now that we have the constant terms calculated above, we can move on with calculating the parameters $P(w_{i}|Spam)$ and $P(w_{i}|Ham)$.\n",
    "\n",
    "$P(w_{i}|Spam)$ and $P(w_{i}|Ham)$ will vary depending on the individual words. For instance, $P(secret|Spam)$ will have a certain probability value, while $P(cousin|Spam)$ or $P(lovely|Spam)$ will most likely have other values.\n",
    "\n",
    "Therefore, each parameter will be a conditional probability value associated with each word in the vocabulary, calculated using the formulas we saw above.\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(w_{i}|Spam) = \\frac{N_{w_{i}|Spam} + \\alpha}{N_{spam} + \\alpha N_{Vocabulary}}$\n",
    "</center>\n",
    "\n",
    "and\n",
    "\n",
    "&nbsp;\n",
    "<center>\n",
    "    $\\displaystyle P(w_{i}|Ham) = \\frac{N_{w_{i}|Ham} + \\alpha}{N_{Ham} + \\alpha N_{Vocabulary}}$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00beec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculate parameters\n",
    "for word in vocabulary:\n",
    "   n_word_given_spam = spam_messages[word].sum() # spam_messages already defined\n",
    "   p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "   parameters_spam[word] = p_word_given_spam\n",
    "\n",
    "   n_word_given_ham = ham_messages[word].sum() # ham_messages already defined\n",
    "   p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "   parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975bbb36",
   "metadata": {},
   "source": [
    "Now that we have all our parameters calculated, we can start creating the spam filter. The spam filter is understood as a function that:\n",
    "\n",
    "* Takes in as input a new message $(w_{1}, w_{2}, ..., w_{n})$.\n",
    "* Calculates $P(Spam|w_{1}, w_{2}, ..., w_{n})$ and $P(Ham|w_{1}, w_{2}, ..., w_{n})$.\n",
    "* Compares the values of $P(Spam|w_{1}, w_{2}, ..., w_{n})$ and $P(Ham|w_{1}, w_{2}, ..., w_{n})$, and:\n",
    "    * If $P(Ham|w_{1}, w_{2}, ..., w_{n}) > P(Spam|w_{1}, w_{2}, ..., w_{n})$, then the message is classified as ham.\n",
    "    * If $P(Ham|w_{1}, w_{2}, ..., w_{n}) < P(Spam|w_{1}, w_{2}, ..., w_{n})$, then the message is classified as spam.\n",
    "    * If $P(Ham|w_{1}, w_{2}, ..., w_{n}) = P(Spam|w_{1}, w_{2}, ..., w_{n})$, then the algorithm may request human help.\n",
    "\n",
    "Note that some new messages will contain words that are not part of the vocabulary. We will simply ignore these words when we're calculating the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb0d105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "   '''\n",
    "   message: a string\n",
    "   '''\n",
    "\n",
    "   message = re.sub('\\W', ' ', message)\n",
    "   message = message.lower().split()\n",
    "\n",
    "   p_spam_given_message = p_spam\n",
    "   p_ham_given_message = p_ham\n",
    "\n",
    "   for word in message:\n",
    "      if word in parameters_spam:\n",
    "         p_spam_given_message *= parameters_spam[word]\n",
    "\n",
    "      if word in parameters_ham: \n",
    "         p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "   print('P(Spam|message):', p_spam_given_message)\n",
    "   print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "   if p_ham_given_message > p_spam_given_message:\n",
    "      print('Label: Ham')\n",
    "   elif p_ham_given_message < p_spam_given_message:\n",
    "      print('Label: Spam')\n",
    "   else:\n",
    "      print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c45da9",
   "metadata": {},
   "source": [
    "Let's try this on a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1137fbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.5223001843661562e-25\n",
      "P(Ham|message): 1.2176099861344542e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6425f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 4.74693224259436e-25\n",
      "P(Ham|message): 2.7878169823581606e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a994f8",
   "metadata": {},
   "source": [
    "Let's modify our classification function so that instead of printing the results it returns it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49fb3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "   '''\n",
    "   message: a string\n",
    "   '''\n",
    "\n",
    "   message = re.sub('\\W', ' ', message)\n",
    "   message = message.lower().split()\n",
    "\n",
    "   p_spam_given_message = p_spam\n",
    "   p_ham_given_message = p_ham\n",
    "\n",
    "   for word in message:\n",
    "      if word in parameters_spam:\n",
    "         p_spam_given_message *= parameters_spam[word]\n",
    "\n",
    "      if word in parameters_ham:\n",
    "         p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "   if p_ham_given_message > p_spam_given_message:\n",
    "      return 'ham'\n",
    "   elif p_spam_given_message > p_ham_given_message:\n",
    "      return 'spam'\n",
    "   else:\n",
    "      return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd9341",
   "metadata": {},
   "source": [
    "Now let's apply this predictive algorithm to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9ad71cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Was playng 9 doors game and gt racing on phone...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>I dont thnk its a wrong calling between us</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>All e best 4 ur exam later.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey what how about your project. Started aha da.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dunno, my dad said he coming home 2 bring us o...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham  Was playng 9 doors game and gt racing on phone...       ham\n",
       "1   ham         I dont thnk its a wrong calling between us       ham\n",
       "2   ham                        All e best 4 ur exam later.       ham\n",
       "3   ham   Hey what how about your project. Started aha da.       ham\n",
       "4   ham  Dunno, my dad said he coming home 2 bring us o...       ham"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c580c",
   "metadata": {},
   "source": [
    "Finally, let's calculate the accuracy of our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9454ab0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1092\n",
      "Incorrect: 22\n",
      "Accuracy: 0.9802513464991023\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "\n",
    "for row in test_set.iterrows():\n",
    "   row = row[1]\n",
    "   if row['Label'] == row['predicted']:\n",
    "      correct += 1\n",
    "\n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066f1856",
   "metadata": {},
   "source": [
    "Pretty good!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2022.05-py39",
   "language": "python",
   "name": "conda-env-anaconda-2022.05-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
