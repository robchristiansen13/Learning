{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gdxr-tZ4_JHf"
      },
      "outputs": [],
      "source": [
        "#initial imports that you may find useful\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#additional imports\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1K_dSlP_UmU"
      },
      "source": [
        "For this assignment you will need to use the sklearn framework to implement a custom Naive Bayes classifier.  The classifier only needs to handle binary data (both the attributes and the classes).  The attributes will always have a value of 0 or 1.  The class labels will always have a value of 1 or -1.  You can use libraries to help with the data processing, calculations, etc, but you must implement your own Na√Øve Bayes algorithm.  Do not use an existing implementation.  One important implementation detail is that you should convert the probabilities to log probabilities to avoid the number becoming to small to represent as a floating point number.  For example instead of computing P(x|c)P(c) compute log(P(x|c)+log(P(c)). Provide your implementation below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFG6O-SBCOyH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# #Your Naive Bayes Implementation goes here.\n",
        "# #Adjust this as you see fit\n",
        "\n",
        "class BinaryNBClassifier(BaseEstimator, ClassifierMixin):        \n",
        "    def __init__(self, k=0.5):\n",
        "        self.k = k\n",
        "        self.word_probs = []\n",
        "\n",
        "    def count_universe(self, X): #Rob: Python lesson learned... when you call using self, you have to accept self as a parameter\n",
        "        event_count, feature_count = X.shape\n",
        "\n",
        "        # Count values per column. This requires transposing the array (from columns to row)\n",
        "        for col in X.T:\n",
        "            print(col)\n",
        "            unique, counts = np.unique(X_train, return_counts=True)\n",
        "            dict(zip(unique, counts)) \n",
        "            print(f\"Unique values: {unique}  Count: {counts}\")\n",
        "\n",
        "\n",
        "        return event_count, feature_count\n",
        "\n",
        "    def word_probabilities(counts, total_spams, total_non_spams, k=0.5):\n",
        "        \"\"\"turn the word_counts into a list of triplets\n",
        "        w, p(w | spam) and p(w | ~spam)\"\"\"\n",
        "        \n",
        "        return [(w,\n",
        "                (spam + k) / (total_spams + 2 * k),\n",
        "                (non_spam + k) / (total_non_spams + 2 * k))\n",
        "                for w, (spam, non_spam) in counts.iteritems()]\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        event_count, feature_count = self.count_universe(X)\n",
        "        print(f\"event_count: {event_count} feature_count: {feature_count}\")\n",
        "        return self\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resources Consulted:\n",
        "* https://sklearn-template.readthedocs.io/en/latest/user_guide.html\n",
        "* https://saturncloud.io/blog/how-to-keep-column-names-when-converting-from-pandas-to-numpy\n",
        "* https://github.com/ApoorvRusia/Naive-Bayes-classification-on-Iris-dataset/blob/master/Naiye%20Bayes%20classification%20application.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('Datasets for Assignment 2/test1_1.csv',)\n",
        "df.info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Spliting the dataset in independent and dependent variables\n",
        "X = df.iloc[:,:-1].to_dict('list') # The idea here is to capture all the columns except the last one as X\n",
        "y = df['Class'].to_dict('records')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Class'].to_dict('split')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1.0, random_state = 42)\n",
        "\n",
        "# For this particular exercise, the instruction is to use all the samples for training and testing\n",
        "\n",
        "X_train = df.iloc[:,:-1].to_dict('list') # Keep all but the last row\n",
        "X_test = df.iloc[:,:-1].to_dict('list') # Keep all but the last row\n",
        "y_train = df.iloc[:,-1:].to_dict('list') # Only keep the last row of Class\n",
        "y_test = df.iloc[:,-1:].to_dict('list') # Only keep the last row Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique, counts = np.unique(X_train.values, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr2 = np.split(X_train, 1, axis=1)  \n",
        "arr2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NBClassifier = BinaryNBClassifier()\n",
        "NBClassifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Train and test your BinaryNBClassifier and the sklearn CategoricalNBClassifier on the datasets from canvas\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "cclassifier = CategoricalNB()\n",
        "cclassifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predicting the set results\n",
        "y_pred = cclassifier.predict(X_train)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#lets see the actual and predicted value side by side\n",
        "y_compare = np.vstack((y_train,y_pred)).T\n",
        "#actual value on the left side and predicted value on the right hand side\n",
        "#printing the top 5 values\n",
        "y_compare[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#finding accuracy from the confusion matrix.\n",
        "a = cm.shape\n",
        "corrPred = 0\n",
        "falsePred = 0\n",
        "\n",
        "for row in range(a[0]):\n",
        "    for c in range(a[1]):\n",
        "        if row == c:\n",
        "            corrPred +=cm[row,c]\n",
        "        else:\n",
        "            falsePred += cm[row,c]\n",
        "print('Correct predictions: ', corrPred)\n",
        "print('False predictions', falsePred)\n",
        "print ('\\n\\nAccuracy of the Categorical Clasification is: ', corrPred/(cm.sum()))   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv24NS1RCpjT"
      },
      "source": [
        "Now you will train and test your Binary Naive Bayes classifier on a few different datasets.  The datasets can be downloaded from canvas.  They are linked in the assignment description.  For this part of the assignment we will not be splitting the data into training, validation and test data sets.  Instead you should use the entire dataset for training and the entire dataset for testing.  You will need to complete the following table (you can just output the results in this format you don't need to copy them into the text field).\n",
        "\n",
        "|dataset|# of instances|# of features | Your NB Training Time | Your NB Test Time | Your NB Accuracy | sklearn CategoricalNB Training Time | sklearn Categorical NB Test Time | sklearn CategoricalNB Accuracy|\n",
        "|-----------|------------|-------------|------------------|-------------------|-------------------------|---------------------------------|------------------------|----------------------------------|\n",
        "test1_1 |\n",
        "test1_2 |\n",
        "test1_4 |\n",
        "test1_5 |\n",
        "test2_1 |\n",
        "test2_2 |\n",
        "test2_4 |\n",
        "test2_5 |\n",
        "test4_1 |\n",
        "test4_2 |\n",
        "test4_4 |\n",
        "test4_5 |\n",
        "test5_1 |\n",
        "test5_2 |\n",
        "test5_4 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6x9Ol9tE0OX"
      },
      "outputs": [],
      "source": [
        "#Train and test your BinaryNBClassifier and the sklearn CategoricalNBClassifier on the datasets from canvas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzzilfSNFGvY"
      },
      "source": [
        "The next step for this assignment is split the vote dataset (also found on canvas) into a *train/test split* (use 20% of the data for testing).  Train both algorithms on the training data using *cross-fold validation* and then report the accuracy, f1-score, mcc and informedness results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi8VaK4V1z_E"
      },
      "outputs": [],
      "source": [
        "#Split the vote dataset\n",
        "#Use cross-validatation to compare BinaryNBClassifier against CategoricalNBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFP5ttuS2AtP"
      },
      "source": [
        "Finally, choose the algorithm that performed the best on the cross-validation, train it on all the training data and test on the test data.  Report the accuracy, f1-score, mcc and informedness results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UquA9oi22X-Q"
      },
      "outputs": [],
      "source": [
        "#Final Generalization test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
