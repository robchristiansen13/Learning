{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resources Consulted:\n",
        "* https://sklearn-template.readthedocs.io/en/latest/user_guide.html\n",
        "* https://saturncloud.io/blog/how-to-keep-column-names-when-converting-from-pandas-to-numpy\n",
        "* https://github.com/ApoorvRusia/Naive-Bayes-classification-on-Iris-dataset/blob/master/Naiye%20Bayes%20classification%20application.ipynb\n",
        "* https://datascience.stackexchange.com/questions/18904/how-do-i-convert-a-pandas-dataframe-to-a-1d-array\n",
        "* https://stackoverflow.com/questions/35996970/typeerror-fit-missing-1-required-positional-argument-y\n",
        "* https://machinelearningmastery.com/bayes-theorem-for-machine-learning/\n",
        "* https://news.ycombinator.com/item?id=21151032\n",
        "* https://www.countbayesie.com/blog/2016/5/1/a-guide-to-bayesian-statistics\n",
        "* **https://www.kdnuggets.com/2020/07/spam-filter-python-naive-bayes-scratch.html**\n",
        "* https://www.kaggle.com/code/marloz/sklearn-pipelines-missing-values/notebook\n",
        "\n",
        "Notes for study from machinelearningmastery link above:\n",
        "\n",
        "The result P(A|B) is referred to as the posterior probability and P(A) is referred to as the prior probability.\n",
        "\n",
        "P(A|B): Posterior probability.\n",
        "P(A): Prior probability.\n",
        "Sometimes P(B|A) is referred to as the likelihood and P(B) is referred to as the evidence.\n",
        "\n",
        "P(B|A): Likelihood.\n",
        "P(B): Evidence.\n",
        "This allows Bayes Theorem to be restated as:\n",
        "\n",
        "Posterior = Likelihood * Prior / Evidence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1K_dSlP_UmU"
      },
      "source": [
        "For this assignment you will need to use the sklearn framework to implement a custom Naive Bayes classifier.  The classifier only needs to handle binary data (both the attributes and the classes).  The attributes will always have a value of 0 or 1.  The class labels will always have a value of 1 or -1.  You can use libraries to help with the data processing, calculations, etc, but you must implement your own Na√Øve Bayes algorithm.  Do not use an existing implementation.  One important implementation detail is that you should convert the probabilities to log probabilities to avoid the number becoming to small to represent as a floating point number.  For example instead of computing P(x|c)P(c) compute log(P(x|c)+log(P(c)). Provide your implementation below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gdxr-tZ4_JHf"
      },
      "outputs": [],
      "source": [
        "#initial imports that you may find useful\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#additional imports\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tFG6O-SBCOyH"
      },
      "outputs": [],
      "source": [
        "# #Your Naive Bayes Implementation goes here.\n",
        "# #Adjust this as you see fit\n",
        "\n",
        "class BinaryNBClassifier(BaseEstimator, ClassifierMixin):        \n",
        "    def __init__(self, k=0.5):\n",
        "        self.k = k\n",
        "        self.word_probs = []\n",
        "             \n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        #  STEP 1: Determine how often the labeled class appears (e.g. spam). This variable is called p_of_b\n",
        "        global total_b, total_not_b\n",
        "        total_b = 0\n",
        "        \n",
        "        self.row_counter = 0\n",
        "        for row in y:\n",
        "            if y[self.row_counter][0] == 1: # Note: Because the not spam values are recorded as -1 rather than 0 we can't simply add up y using np.sum(y)\n",
        "                total_b += 1\n",
        "            self.row_counter += 1\n",
        "        total_not_b = len(y) - total_b\n",
        "        \n",
        "        #   We will need the following two values later in the predict() function so we need to make sure they are in scope\n",
        "        global p_of_b\n",
        "        global p_of_not_b\n",
        "\n",
        "        p_of_b = total_b / len(y) # This is how often the B event happens in the universe of labeled classifications\n",
        "        p_of_not_b = 1 - p_of_b\n",
        "\n",
        "        # print(f\"p_of_b: {p_of_b} p_of_not_b: {p_of_not_b}\")\n",
        "        # print(f\"log10(p_of_b): {np.log10(p_of_b)} log10(p_of_not_b): {np.log10(p_of_not_b)}\")\n",
        "\n",
        "        # STEP 2: With the constants in place we can look at the probability of the features when B is true/not true\n",
        "        \n",
        "        #   Prepopulate a single dimension array of length \"feature_count\" with 0s\n",
        "        global X_row_count, X_column_count\n",
        "        X_row_count, X_column_count = np.shape(X)\n",
        "\n",
        "        global y_row_count, y_column_count\n",
        "        y_row_count, y_column_count = np.shape(y)\n",
        "\n",
        "        self.count_of_feature_A_when_b = np.full(X_column_count, 0) \n",
        "        self.count_of_feature_A_when_not_b = np.full(X_column_count, 0)\n",
        "        self.count_of_feature_not_A_when_b = np.full(X_column_count, 0) \n",
        "        self.count_of_feature_not_A_when_not_b = np.full(X_column_count, 0)\n",
        "\n",
        "        #   For each event, go through each feature. Increment the appropriate counter based on whether the word appears when B is true / not true\n",
        "        self.row_counter = 0\n",
        "        self.column_counter = 0\n",
        "        self.evaluate_A_feature = int\n",
        "        self.evaluate_B_feature = int\n",
        "\n",
        "        for row in X:\n",
        "            for value in row:\n",
        "                # The following rows setup the condition to search for\n",
        "                self.evaluate_A_feature = X[self.row_counter][self.column_counter]\n",
        "                self.evaluate_B_feature = y[self.row_counter][0]\n",
        "\n",
        "                if (self.evaluate_A_feature == 1 and self.evaluate_B_feature == 1):\n",
        "                    self.count_of_feature_A_when_b[self.column_counter] += 1\n",
        "                elif (self.evaluate_A_feature == 1 and self.evaluate_B_feature != 1):\n",
        "                    self.count_of_feature_A_when_not_b[self.column_counter] += 1\n",
        "                elif (self.evaluate_A_feature != 1 and self.evaluate_B_feature == 1):\n",
        "                    self.count_of_feature_not_A_when_b[self.column_counter] += 1\n",
        "                elif (self.evaluate_A_feature != 1 and self.evaluate_B_feature != 1):\n",
        "                    self.count_of_feature_not_A_when_not_b[self.column_counter] += 1\n",
        "                self.column_counter += 1                \n",
        "            self.column_counter = 0\n",
        "            self.row_counter += 1\n",
        "\n",
        "        # print(f\"count_of_feature_A_when_b: {self.count_of_feature_A_when_b}\")\n",
        "        # print(f\"count_of_feature_A_when_not_b: {self.count_of_feature_A_when_not_b}\")\n",
        "        # print(f\"count_of_feature_not_A_when_b: {self.count_of_feature_not_A_when_b}\")\n",
        "        # print(f\"count_of_feature_not_A_when_not_b: {self.count_of_feature_not_A_when_not_b}\")\n",
        "\n",
        "        #   Having calculated the count of each identified feature, we can now calculate the probabilities of each feature as it appears in B, not B, and total\n",
        "        global prob_of_feature_A_when_b        \n",
        "        global prob_of_feature_A_when_not_b\n",
        "        global prob_of_feature_not_A_when_b\n",
        "        global prob_of_feature_not_A_when_not_b\n",
        "        prob_of_feature_A_when_b = []\n",
        "        prob_of_feature_A_when_not_b = []\n",
        "        prob_of_feature_not_A_when_b = []\n",
        "        prob_of_feature_not_A_when_not_b = []\n",
        "\n",
        "        prob_of_feature_A_when_b = np.divide(self.count_of_feature_A_when_b, total_b) # The number of times the A feature occurs given B / Number of events marked B\n",
        "        prob_of_feature_A_when_not_b = np.divide(self.count_of_feature_A_when_not_b, total_not_b) # The number of times the A feature occurs given B / Number of events marked B\n",
        "        prob_of_feature_not_A_when_b = np.divide(self.count_of_feature_not_A_when_b, total_b) # The number of times the A feature occurs given B / Number of events marked B\n",
        "        prob_of_feature_not_A_when_not_b = np.divide(self.count_of_feature_not_A_when_not_b, total_not_b) # The number of times the A feature occurs given B / Number of events marked B\n",
        "\n",
        "        # print(f\"prob_of_feature_A_when_b: {prob_of_feature_A_when_b}\")\n",
        "        # print(f\"prob_of_feature_A_when_not_b: {prob_of_feature_A_when_not_b}\")\n",
        "        # print(f\"prob_of_feature_not_A_when_b: {prob_of_feature_not_A_when_b}\")\n",
        "        # print(f\"prob_of_feature_not_A_when_not_b: {prob_of_feature_not_A_when_not_b}\")\n",
        "\n",
        "\n",
        "        # # END: At this point, we have all the calculations required for what is necessary in the predict method\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "\n",
        "        import math\n",
        "\n",
        "        # The predict function accepts N events with M features to make a classification using the Naive Bayes implementation\n",
        "        # We want to multiply the existence of a feature (or lack thereof) by the probability that feature appears in the B (or not B) labeled training set\n",
        "\n",
        "        num_rows, num_cols = X.shape\n",
        "        y_predicted = np.full(num_rows, 0) \n",
        "\n",
        "        self.row_counter = 0\n",
        "        for row in X:\n",
        "            # print(f\"X: {row}\")\n",
        "\n",
        "            # Using the numpy multiply operator we can multiple each 'cell' by the corresponding 'cell'\n",
        "            prob_of_feature_A_when_b_weighted = np.multiply(row, prob_of_feature_A_when_b)\n",
        "            prob_of_feature_A_when_not_b_weighted = np.multiply(row, prob_of_feature_A_when_not_b)\n",
        "\n",
        "            # We need to swap out the 1s and 0s in the training set so we can multiply the 'not As' to get probabilities\n",
        "            # print(f\"row: {row} row_mirrored: {abs(row-1)}\") # Checking to make sure this value does what I expect: YES\n",
        "            prob_of_feature_not_A_when_b_weighted = np.multiply(abs(row-1), prob_of_feature_not_A_when_b) # BIG THOUGHT REQUIRED HERE. NEED TO ASSERT A TRUE WHEN THE FEATURE IS FALSE\n",
        "            prob_of_feature_not_A_when_not_b_weighted = np.multiply(abs(row-1), prob_of_feature_not_A_when_not_b)\n",
        "\n",
        "            # With the probabilities of each feature we can now add the log() scores together\n",
        "            #   Note:   It's common for the probabilities for some of the features to come back zero\n",
        "            #           However the np.log function breaks when trying to take the log(0) since there's no exponent that will get the base value to zero\n",
        "            #           Since we no longer care about the order of the values, we can np.sort(), then np.trim_zeros to get rid of leading or trailing zeros\n",
        "            #           before we take the log()        \n",
        "   \n",
        "        \n",
        "            prob_of_feature_A_when_b_weighted_log = np.sum(np.log10(np.trim_zeros(np.sort(prob_of_feature_A_when_b_weighted))))/num_cols\n",
        "            prob_of_feature_A_when_not_b_weighted_log = np.sum(np.log10(np.trim_zeros(np.sort(prob_of_feature_A_when_not_b_weighted))))/num_cols\n",
        "            prob_of_feature_not_A_when_b_weighted_log = np.sum(np.log10(np.trim_zeros(np.sort(prob_of_feature_not_A_when_b_weighted))))/num_cols\n",
        "            prob_of_feature_not_A_when_not_b_weighted_log = np.sum(np.log10(np.trim_zeros(np.sort(prob_of_feature_not_A_when_not_b_weighted))))/num_cols\n",
        "\n",
        "            # Look into the math operations:\n",
        "            # print(f\"prob_of_B_given_A = ({prob_of_feature_A_when_b_weighted_log} + {prob_of_feature_not_A_when_b_weighted_log} + {math.log10(p_of_b)}\")\n",
        "            # print(f\"prob_of_not_B_given_A =  ({prob_of_feature_A_when_not_b_weighted_log} + {prob_of_feature_not_A_when_not_b_weighted_log} + {math.log10(p_of_not_b)}\") # ** is the operator for raising a value to that power\n",
        "\n",
        "            prob_of_B_given_A = (prob_of_feature_A_when_b_weighted_log + prob_of_feature_not_A_when_b_weighted_log + np.log10(p_of_b)) # Intentionally NOT raising this back to 10** so I can see the values else it prints 0.0\n",
        "            prob_of_not_B_given_A =  (prob_of_feature_A_when_not_b_weighted_log + prob_of_feature_not_A_when_not_b_weighted_log + np.log10(p_of_not_b)) # ** is the operator for raising a value to that power\n",
        "\n",
        "            # print(f\"Row {self.row_counter}: prob_of_B_given_A: {prob_of_B_given_A} vs prob_of_not_B_given_A: {prob_of_not_B_given_A}\")\n",
        "\n",
        "            if prob_of_B_given_A >= prob_of_not_B_given_A: \n",
        "                y_predicted[self.row_counter] = 1\n",
        "            else:\n",
        "                y_predicted[self.row_counter] = -1\n",
        "\n",
        "            # print(f\"y_predicted: {y_predicted[self.row_counter]}\")\n",
        "            \n",
        "            self.row_counter += 1\n",
        "\n",
        "        # print(f\"y_predicted: {y_predicted}\")\n",
        "        return np.array(y_predicted) # For a long time I was returning self\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define pipelines\n",
        "\n",
        "from sklearn.pipeline import Pipeline # For setting up pipeline\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "NBClassifier_pipe = Pipeline([\n",
        "# ('scaler', StandardScaler()), # Not necessary for this exercise\n",
        "# ('selector', VarianceThreshold()), # Not necessary for this exercise\n",
        "('imputer', SimpleImputer(strategy='most_frequent')), # Impute the values when missing values\n",
        "('classifier', BinaryNBClassifier())\n",
        "])\n",
        "\n",
        "CategoricalNB_pipe = Pipeline([\n",
        "# ('scaler', StandardScaler()), # Not necessary for this exercise\n",
        "# ('selector', VarianceThreshold()), # Not necessary for this exercise\n",
        "('imputer', SimpleImputer(strategy='most_frequent')), # Impute the values when missing values\n",
        "('classifier', CategoricalNB())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv24NS1RCpjT"
      },
      "source": [
        "Now you will train and test your Binary Naive Bayes classifier on a few different datasets.  The datasets can be downloaded from canvas.  They are linked in the assignment description.  For this part of the assignment we will not be splitting the data into training, validation and test data sets.  Instead you should use the entire dataset for training and the entire dataset for testing.  You will need to complete the following table (you can just output the results in this format you don't need to copy them into the text field).\n",
        "\n",
        "|dataset|# of instances|# of features | Your NB Training Time | Your NB Test Time | Your NB Accuracy | sklearn CategoricalNB Training Time | sklearn Categorical NB Test Time | sklearn CategoricalNB Accuracy|\n",
        "|-----------|------------|-------------|------------------|-------------------|-------------------------|---------------------------------|------------------------|----------------------------------|\n",
        "test1_1 |\n",
        "test1_2 |\n",
        "test1_4 |\n",
        "test1_5 |\n",
        "test2_1 |\n",
        "test2_2 |\n",
        "test2_4 |\n",
        "test2_5 |\n",
        "test4_1 |\n",
        "test4_2 |\n",
        "test4_4 |\n",
        "test4_5 |\n",
        "test5_1 |\n",
        "test5_2 |\n",
        "test5_4 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|dataset\t|# of instances\t|# of features\t|Your NB Training Time\t|Your NB Test Time\t|Your NB Accuracy\t|sklearn CategoricalNB Training Time\t|sklearn Categorical NB Test Time\t|sklearn CategoricalNB Accuracy\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test1_1\t|10\t\t|10\t\t|0.001348\t\t|0.000485\t\t|0.8\t\t\t|0.002883\t\t\t\t|0.000124\t\t\t\t|0.9\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test1_2\t|10\t\t|100\t\t|0.010266\t\t|0.00042\t\t|1.0\t\t\t|0.012633\t\t\t\t|0.000214\t\t\t\t|1.0\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test1_4\t|10\t\t|10000\t\t|0.966381\t\t|0.016033\t\t|0.7\t\t\t|1.139847\t\t\t\t|0.011303\t\t\t\t|1.0\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test1_5\t|10\t\t|100000\t\t|10.876733\t\t|0.172881\t\t|1.0\t\t\t|11.029003\t\t\t\t|0.111004\t\t\t\t|1.0\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test2_1\t|100\t\t|10\t\t|0.001995\t\t|0.00165\t\t|0.9\t\t\t|0.023852\t\t\t\t|0.000164\t\t\t\t|0.9\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test2_2\t|100\t\t|100\t\t|0.013615\t\t|0.003182\t\t|0.96\t\t\t|0.011938\t\t\t\t|0.000277\t\t\t\t|0.97\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test2_4\t|100\t\t|10000\t\t|1.395075\t\t|0.18327\t\t|0.94\t\t\t|1.133817\t\t\t\t|0.018536\t\t\t\t|0.93\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test2_5\t|100\t\t|100000\t\t|14.052571\t\t|1.946095\t\t|0.96\t\t\t|11.265875\t\t\t\t|0.191715\t\t\t\t|0.96\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test4_1\t|10000\t\t|10\t\t|0.050903\t\t|0.169782\t\t|0.8253\t\t\t|0.020415\t\t\t\t|0.001326\t\t\t\t|0.8246\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test4_2\t|10000\t\t|100\t\t|0.459417\t\t|0.302303\t\t|0.9524\t\t\t|0.035215\t\t\t\t|0.009598\t\t\t\t|0.9523\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test4_5\t|10000\t\t|100000\t\t|581.911719\t\t|251.617472\t\t|0.9519\t\t\t|47.702876\t\t\t\t|17.391921\t\t\t\t|0.9519\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test5_1\t|100000\t\t|10\t\t|0.528538\t\t|1.575522\t\t|0.8716\t\t\t|0.051063\t\t\t\t|0.011041\t\t\t\t|0.87147\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test5_2\t|100000\t\t|100\t\t|4.332254\t\t|2.981554\t\t|0.94725\t\t\t|0.247888\t\t\t\t|0.100991\t\t\t\t|0.94728\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test5_4\t|100000\t\t|10000\t\t|459.923817\t\t|231.028875\t\t|0.94919\t\t\t|40.486339\t\t\t\t|18.606741\t\t\t\t|0.94919\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n"
          ]
        }
      ],
      "source": [
        "#Train and test your BinaryNBClassifier and the sklearn CategoricalNBClassifier on the datasets from canvas\n",
        "\n",
        "# Loop through files in directory:\n",
        "\n",
        "# import required modules\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "# def evaluate_results(y_train,y_pred):\n",
        "\n",
        "# assign directory\n",
        "directory = 'Datasets for Assignment 2'\n",
        "\n",
        "# print header\n",
        "print(\"|dataset\\t|# of instances\\t|# of features\\t|Your NB Training Time\\t|Your NB Test Time\\t|Your NB Accuracy\\t|sklearn CategoricalNB Training Time\\t|sklearn Categorical NB Test Time\\t|sklearn CategoricalNB Accuracy\\t|\")\n",
        " \n",
        "# iterate over files in directory\n",
        "for filename in sorted(os.listdir(directory)):    \n",
        "    if not filename.startswith('.') and filename != \"vote.csv\": # This command excludes the .DS_Store common on Mac OS  : and filename == \"test1_4.csv\"\n",
        "        f = os.path.join(directory, filename)\n",
        "        # checking if it is a file\n",
        "        if os.path.isfile(f):\n",
        "            # print(f)\n",
        "            df = pd.DataFrame()\n",
        "            df = pd.read_csv(f,)\n",
        "            df.info\n",
        "            \n",
        "            # Prepare the data\n",
        "\n",
        "            #   The values for the Events are up to the last column\n",
        "            #   X = np.zeros(1) # Reset the array\n",
        "            X = df.iloc[:,:-1].values # The values are everything but the last column\n",
        "            \n",
        "            #   The values for the Classification are in the last column\n",
        "            y = df.iloc[:,-1:].values\n",
        "\n",
        "            # Splitting the dataset into the Training set and Test set\n",
        "            # from sklearn.model_selection import train_test_split\n",
        "            # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)\n",
        "\n",
        "            # However for this particular exercise, the instruction is to use all the samples for training and testing\n",
        "            X_train = X\n",
        "            y_train = y\n",
        "\n",
        "            X_test = X\n",
        "            y_test = y\n",
        "\n",
        "            num_instances, num_features = np.shape(X_train)\n",
        "\n",
        "            # Call pipelines\n",
        "            CategoricalNB_fit_start =  time.time() # Returns Unix epoch time\n",
        "            CategoricalNB_pipe.fit(X_train, y_train.ravel())\n",
        "            CategoricalNB_fit_end =  time.time() # Returns Unix epoch time\n",
        "            CategoricalNB_fit_seconds_elapsed = round(CategoricalNB_fit_end - CategoricalNB_fit_start, 6)\n",
        "\n",
        "            CategoricalNB_predict = CategoricalNB_pipe.predict(X_train)\n",
        "            CategoricalNB_predict_end =  time.time() # Returns Unix epoch time\n",
        "            CategoricalNB_predict_seconds_elapsed = round(CategoricalNB_predict_end - CategoricalNB_fit_end, 6)\n",
        "            CategoricalNB_accuracy =  accuracy_score(y_train, CategoricalNB_predict)\n",
        "\n",
        "\n",
        "            NBClassifier_fit_start =  time.time() # Returns Unix epoch time\n",
        "            NBClassifier_pipe.fit(X_train, y_train)\n",
        "            NBClassifier_fit_end =  time.time() # Returns Unix epoch time\n",
        "            NBClassifier_fit_seconds_elapsed = round(NBClassifier_fit_end - NBClassifier_fit_start, 6)\n",
        "\n",
        "            NBClassifier_predict = NBClassifier_pipe.predict(X_train)\n",
        "            NBClassifier_predict_end =  time.time() # Returns Unix epoch time\n",
        "            NBClassifier_predict_seconds_elapsed = round(NBClassifier_predict_end - NBClassifier_fit_end, 6)\n",
        "            NBClassifier_accuracy =  accuracy_score(y_train, NBClassifier_predict)\n",
        "            # print(f\"NBClassifier accuracy: {NBClassifier_accuracy}\")\n",
        "            \n",
        "            print(\"|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\")\n",
        "            print(f\"|{filename[:-4]}\\t|{num_instances}\\t\\t|{num_features}\\t\\t|{NBClassifier_fit_seconds_elapsed}\\t\\t|{NBClassifier_predict_seconds_elapsed}\\t\\t|{NBClassifier_accuracy}\\t\\t\\t|{CategoricalNB_fit_seconds_elapsed}\\t\\t\\t\\t|{CategoricalNB_predict_seconds_elapsed}\\t\\t\\t\\t|{CategoricalNB_accuracy}\\t\\t\\t\\t|\")\n",
        "print(\"|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzzilfSNFGvY"
      },
      "source": [
        "The next step for this assignment is split the vote dataset (also found on canvas) into a *train/test split* (use 20% of the data for testing).  Train both algorithms on the training data using *cross-fold validation* and then report the accuracy, f1-score, mcc and informedness results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|dataset\t|# of instances\t|# of features\t|Your NB Training Time\t|Your NB Test Time\t|Your NB Accuracy\t|sklearn CategoricalNB Training Time\t|sklearn Categorical NB Test Time\t|sklearn CategoricalNB Accuracy\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|vote\t\t|391\t\t|17\t\t|0.005095\t\t|0.006629\t\t|0.9104859335038363\t|0.007196\t\t\t\t|0.000219\t\t\t\t|0.9156010230179028\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n"
          ]
        }
      ],
      "source": [
        "#Split the vote dataset\n",
        "#Use cross-validatation to compare BinaryNBClassifier against CategoricalNBClassifier\n",
        "\n",
        "# Loop through files in directory:\n",
        "\n",
        "# import required modules\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, balanced_accuracy_score # balanced_accuracy_score with adjusted=True is Informedness\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "# def evaluate_results(y_train,y_pred):\n",
        "\n",
        "# assign directory\n",
        "directory = 'Datasets for Assignment 2'\n",
        "\n",
        "# print header\n",
        "print(\"|dataset\\t|# of instances\\t|# of features\\t|Your NB Training Time\\t|Your NB Test Time\\t|Your NB Accuracy\\t|sklearn CategoricalNB Training Time\\t|sklearn Categorical NB Test Time\\t|sklearn CategoricalNB Accuracy\\t|\")\n",
        " \n",
        "# iterate over files in directory\n",
        "for filename in sorted(os.listdir(directory)):    \n",
        "    if not filename.startswith('.') and filename == \"vote.csv\": # This command excludes the .DS_Store common on Mac OS  : and filename == \"test1_4.csv\"\n",
        "        f = os.path.join(directory, filename)\n",
        "        # checking if it is a file\n",
        "        if os.path.isfile(f):\n",
        "            # print(f)\n",
        "            df = pd.DataFrame()\n",
        "            df = pd.read_csv(f,)\n",
        "            df.info\n",
        "            \n",
        "            # Prepare the data\n",
        "\n",
        "            #   The values for the Events are up to the last column\n",
        "            #   X = np.zeros(1) # Reset the array\n",
        "            X = df.iloc[:,:-1].values # The values are everything but the last column\n",
        "            \n",
        "            #   The values for the Classification are in the last column\n",
        "            y = df.iloc[:,-1:].values\n",
        "\n",
        "            # Splitting the dataset into the Training set and Test set\n",
        "            from sklearn.model_selection import train_test_split\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)\n",
        "\n",
        "            num_instances, num_features = np.shape(X_train)\n",
        "\n",
        "            # Call pipelines\n",
        "            CategoricalNB_fit_start =  time.time() # Returns Unix epoch time\n",
        "            CategoricalNB_pipe.fit(X_train, y_train.ravel())\n",
        "            CategoricalNB_fit_end =  time.time() # Returns Unix epoch time\n",
        "            CategoricalNB_fit_seconds_elapsed = round(CategoricalNB_fit_end - CategoricalNB_fit_start, 6)\n",
        "\n",
        "            CategoricalNB_predict = CategoricalNB_pipe.predict(X_train)\n",
        "            CategoricalNB_predict_end =  time.time() # Returns Unix epoch time\n",
        "            CategoricalNB_predict_seconds_elapsed = round(CategoricalNB_predict_end - CategoricalNB_fit_end, 6)\n",
        "            CategoricalNB_accuracy =  accuracy_score(y_train, CategoricalNB_predict)\n",
        "\n",
        "\n",
        "            NBClassifier_fit_start =  time.time() # Returns Unix epoch time\n",
        "            NBClassifier_pipe.fit(X_train, y_train)\n",
        "            NBClassifier_fit_end =  time.time() # Returns Unix epoch time\n",
        "            NBClassifier_fit_seconds_elapsed = round(NBClassifier_fit_end - NBClassifier_fit_start, 6)\n",
        "\n",
        "            NBClassifier_predict = NBClassifier_pipe.predict(X_train)\n",
        "            NBClassifier_predict_end =  time.time() # Returns Unix epoch time\n",
        "            NBClassifier_predict_seconds_elapsed = round(NBClassifier_predict_end - NBClassifier_fit_end, 6)\n",
        "            NBClassifier_accuracy =  accuracy_score(y_train, NBClassifier_predict)\n",
        "            # print(f\"NBClassifier accuracy: {NBClassifier_accuracy}\")\n",
        "            \n",
        "            print(\"|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\")\n",
        "            print(f\"|{filename[:-4]}\\t\\t|{num_instances}\\t\\t|{num_features}\\t\\t|{NBClassifier_fit_seconds_elapsed}\\t\\t|{NBClassifier_predict_seconds_elapsed}\\t\\t|{NBClassifier_accuracy}\\t|{CategoricalNB_fit_seconds_elapsed}\\t\\t\\t\\t|{CategoricalNB_predict_seconds_elapsed}\\t\\t\\t\\t|{CategoricalNB_accuracy}\\t\\t|\")\n",
        "            \n",
        "print(\"|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFP5ttuS2AtP"
      },
      "source": [
        "Finally, choose the algorithm that performed the best on the cross-validation, train it on all the training data and test on the test data.  Report the accuracy, f1-score, mcc and informedness results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cv_myNBClassifier: 0.9054203180785461\n",
            "cv_CategoricalNB: 0.9073758519961052\n",
            "Conclusion: The CategoricalNB is slightly better\n",
            "\n",
            "CategoricalNB F1 Score: 0.8945686900958466 MCC: <function matthews_corrcoef at 0x1776b36a0> Informedness: 0.8378976486860306\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def warn(*args, **kwargs): #Was getting a warning so I suppressed warnings: \"IndexError: index 434 is out of bounds for axis 1 with size 434\"\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "\n",
        "# Perform testing with cross validation\n",
        "myNBClassifier = NBClassifier_pipe\n",
        "cv_myNBClassifier = cross_val_score(myNBClassifier, X_train, y_train, cv=5)\n",
        "print(f\"cv_myNBClassifier: {np.mean(cv_myNBClassifier[~np.isnan(cv_myNBClassifier)])}\") # Have to handle NaN values\n",
        "\n",
        "myCategoricalNB = CategoricalNB_pipe\n",
        "cv_CategoricalNB = cross_val_score(myCategoricalNB, X_train, y_train.ravel(), cv=5)\n",
        "print(f\"cv_CategoricalNB: {np.mean(cv_CategoricalNB[~np.isnan(cv_CategoricalNB)])}\") # Have to handle NaN values\n",
        "print(\"Conclusion: The CategoricalNB is slightly better\")\n",
        "\n",
        "print()\n",
        "my_f1_score = f1_score(y_train, CategoricalNB_predict)\n",
        "my_mcc_score = matthews_corrcoef(y_train, CategoricalNB_predict)\n",
        "my_balanced_accuracy_score = balanced_accuracy_score(y_train, CategoricalNB_predict, adjusted=True)\n",
        "print(f\"CategoricalNB F1 Score: {my_f1_score} MCC: {matthews_corrcoef} Informedness: {my_balanced_accuracy_score}\")\n",
        "print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UquA9oi22X-Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CategoricalNB F1 Score: 0.8717948717948718 MCC: <function matthews_corrcoef at 0x1776b36a0> Informedness: 0.7905982905982905\n",
            "Conclusion: Some generalization error is present, but it is not extreme. I would feel comfortable moving ahead with this model for classifying the vote data\n"
          ]
        }
      ],
      "source": [
        "#Final Generalization test\n",
        "CategoricalNB_predict = CategoricalNB_pipe.predict(X_test)\n",
        "my_f1_score = f1_score(y_test, CategoricalNB_predict)\n",
        "my_mcc_score = matthews_corrcoef(y_test, CategoricalNB_predict)\n",
        "my_balanced_accuracy_score = balanced_accuracy_score(y_test, CategoricalNB_predict, adjusted=True)\n",
        "print(f\"CategoricalNB F1 Score: {my_f1_score} MCC: {matthews_corrcoef} Informedness: {my_balanced_accuracy_score}\")\n",
        "\n",
        "print(\"Conclusion: Some generalization error is present, but it is not extreme. I would feel comfortable moving ahead with this model for classifying the vote data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*What follows are code snippets I used in working on this assignment*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/m0/ggccpqsn2kj_43nbhzzcn79m0000gp/T/ipykernel_46199/4053474029.py:2: RuntimeWarning: divide by zero encountered in log10\n",
            "  np.log10([.1, 0, .01, .001])\n",
            "/var/folders/m0/ggccpqsn2kj_43nbhzzcn79m0000gp/T/ipykernel_46199/4053474029.py:3: RuntimeWarning: divide by zero encountered in log10\n",
            "  np.log10(np.sort([.1, 0, .01, .001]))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1e-06"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check np operations to validate they are doing what I think they are doing:\n",
        "np.log10([.1, 0, .01, .001])\n",
        "np.log10(np.sort([.1, 0, .01, .001]))\n",
        "np.log10(np.trim_zeros(np.sort([.1, 0, .01, .001])))\n",
        "np.sum(np.log10(np.trim_zeros(np.sort([.1, 0, .01, .001]))))\n",
        "10**(np.sum(np.log10(np.trim_zeros(np.sort([.1, 0, .01, .001])))))\n",
        ".1 * .01 * .001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#lets see the actual and predicted value side by side\n",
        "# y_compare = np.vstack((y_train.ravel(),NBClassifier_predict)).T\n",
        "#actual value on the left side and predicted value on the right hand side\n",
        "#printing the top 5 values\n",
        "# y_compare[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell remains as a reminder of a LOT of work I did to try to maintain the words with their 'labels'. \n",
        "\n",
        "#Spliting the dataset in independent and dependent variables\n",
        "# X = df.iloc[:,:-1].to_dict('list') # The idea here is to capture all the columns except the last one as X\n",
        "# y = df['Class'].to_dict('records')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
