{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resources Consulted:\n",
        "* https://sklearn-template.readthedocs.io/en/latest/user_guide.html\n",
        "* https://saturncloud.io/blog/how-to-keep-column-names-when-converting-from-pandas-to-numpy\n",
        "* https://github.com/ApoorvRusia/Naive-Bayes-classification-on-Iris-dataset/blob/master/Naiye%20Bayes%20classification%20application.ipynb\n",
        "* https://datascience.stackexchange.com/questions/18904/how-do-i-convert-a-pandas-dataframe-to-a-1d-array\n",
        "* https://stackoverflow.com/questions/35996970/typeerror-fit-missing-1-required-positional-argument-y\n",
        "* https://machinelearningmastery.com/bayes-theorem-for-machine-learning/\n",
        "* https://news.ycombinator.com/item?id=21151032\n",
        "* https://www.countbayesie.com/blog/2016/5/1/a-guide-to-bayesian-statistics\n",
        "* **https://www.kdnuggets.com/2020/07/spam-filter-python-naive-bayes-scratch.html**\n",
        "* https://www.kaggle.com/code/marloz/sklearn-pipelines-missing-values/notebook\n",
        "\n",
        "Notes for study from machinelearningmastery link above:\n",
        "\n",
        "The result P(A|B) is referred to as the posterior probability and P(A) is referred to as the prior probability.\n",
        "\n",
        "P(A|B): Posterior probability.\n",
        "P(A): Prior probability.\n",
        "Sometimes P(B|A) is referred to as the likelihood and P(B) is referred to as the evidence.\n",
        "\n",
        "P(B|A): Likelihood.\n",
        "P(B): Evidence.\n",
        "This allows Bayes Theorem to be restated as:\n",
        "\n",
        "Posterior = Likelihood * Prior / Evidence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1K_dSlP_UmU"
      },
      "source": [
        "For this assignment you will need to use the sklearn framework to implement a custom Naive Bayes classifier.  The classifier only needs to handle binary data (both the attributes and the classes).  The attributes will always have a value of 0 or 1.  The class labels will always have a value of 1 or -1.  You can use libraries to help with the data processing, calculations, etc, but you must implement your own Na√Øve Bayes algorithm.  Do not use an existing implementation.  One important implementation detail is that you should convert the probabilities to log probabilities to avoid the number becoming to small to represent as a floating point number.  For example instead of computing P(x|c)P(c) compute log(P(x|c)+log(P(c)). Provide your implementation below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gdxr-tZ4_JHf"
      },
      "outputs": [],
      "source": [
        "#initial imports that you may find useful\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#additional imports\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "tFG6O-SBCOyH"
      },
      "outputs": [],
      "source": [
        "# #Your Naive Bayes Implementation goes here.\n",
        "# #Adjust this as you see fit\n",
        "\n",
        "class BinaryNBClassifier(BaseEstimator, ClassifierMixin):        \n",
        "    def __init__(self, k=0.5):\n",
        "        self.k = k\n",
        "        self.word_probs = []\n",
        "             \n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        #  STEP 1: Determine how often the labeled class appears (e.g. spam). This variable is called p_of_b\n",
        "        global total_b, total_not_b\n",
        "        total_b = 0\n",
        "        \n",
        "        self.row_counter = 0\n",
        "        for row in y:\n",
        "            if y[self.row_counter][0] == 1: # Note: Because the not spam values are recorded as -1 rather than 0 we can't simply add up y using np.sum(y)\n",
        "                total_b += 1\n",
        "            self.row_counter += 1\n",
        "        total_not_b = len(y) - total_b\n",
        "        \n",
        "        #   We will need the following two values later in the predict() function so we need to make sure they are in scope\n",
        "        global p_of_b\n",
        "        global p_of_not_b\n",
        "\n",
        "        p_of_b = total_b / len(y) # This is how often the B event happens in the universe of labeled classifications\n",
        "        p_of_not_b = 1 - p_of_b\n",
        "\n",
        "        print(f\"p_of_b: {p_of_b} p_of_not_b: {p_of_not_b}\")\n",
        "\n",
        "        # STEP 2: With the constants in place we can look at the probability of the features when B is true/not true\n",
        "        \n",
        "        #   Prepopulate a single dimension array of length \"feature_count\" with 0s\n",
        "        global X_row_count, X_column_count\n",
        "        X_row_count, X_column_count = np.shape(X)\n",
        "\n",
        "        global y_row_count, y_column_count\n",
        "        y_row_count, y_column_count = np.shape(y)\n",
        "\n",
        "        self.count_of_feature_A_when_b = np.full(X_column_count, 0) \n",
        "        self.count_of_feature_A_when_not_b = np.full(X_column_count, 0)\n",
        "        self.count_of_feature_not_A_when_b = np.full(X_column_count, 0) \n",
        "        self.count_of_feature_not_A_when_not_b = np.full(X_column_count, 0)\n",
        "\n",
        "        #   For each event, go through each feature. Increment the appropriate counter based on whether the word appears when B is true / not true\n",
        "        self.row_counter = 0\n",
        "        self.column_counter = 0\n",
        "        self.evaluate_A_feature = int\n",
        "        self.evaluate_B_feature = int\n",
        "\n",
        "        for row in X:\n",
        "            for value in row:\n",
        "                # The following rows setup the condition to search for\n",
        "                self.evaluate_A_feature = X[self.row_counter][self.column_counter]\n",
        "                self.evaluate_B_feature = y[self.row_counter][0]\n",
        "\n",
        "                if (self.evaluate_A_feature == 1 and self.evaluate_B_feature == 1):\n",
        "                    self.count_of_feature_A_when_b[self.column_counter] += 1\n",
        "                elif (self.evaluate_A_feature == 1 and self.evaluate_B_feature != 1):\n",
        "                    self.count_of_feature_A_when_not_b[self.column_counter] += 1\n",
        "                elif (self.evaluate_A_feature != 1 and self.evaluate_B_feature == 1):\n",
        "                    self.count_of_feature_not_A_when_b[self.column_counter] += 1\n",
        "                elif (self.evaluate_A_feature != 1 and self.evaluate_B_feature != 1):\n",
        "                    self.count_of_feature_not_A_when_not_b[self.column_counter] += 1\n",
        "                self.column_counter += 1                \n",
        "            self.column_counter = 0\n",
        "            self.row_counter += 1\n",
        "\n",
        "        print(f\"count_of_feature_A_when_b: {self.count_of_feature_A_when_b}\")\n",
        "        print(f\"count_of_feature_A_when_not_b: {self.count_of_feature_A_when_not_b}\")\n",
        "        print(f\"count_of_feature_not_A_when_b: {self.count_of_feature_not_A_when_b}\")\n",
        "        print(f\"count_of_feature_not_A_when_not_b: {self.count_of_feature_not_A_when_not_b}\")\n",
        "\n",
        "        #   Having calculated the count of each identified feature, we can now calculate the probabilities of each feature as it appears in B, not B, and total\n",
        "        global prob_of_feature_A_when_b        \n",
        "        global prob_of_feature_A_when_not_b\n",
        "        global prob_of_feature_not_A_when_b\n",
        "        global prob_of_feature_not_A_when_not_b\n",
        "        prob_of_feature_A_when_b = []\n",
        "        prob_of_feature_A_when_not_b = []\n",
        "        prob_of_feature_not_A_when_b = []\n",
        "        prob_of_feature_not_A_when_not_b = []\n",
        "\n",
        "        prob_of_feature_A_when_b = np.divide(self.count_of_feature_A_when_b, total_b) # The number of times the A feature occurs given B / Number of events marked B\n",
        "        prob_of_feature_A_when_not_b = np.divide(self.count_of_feature_A_when_not_b, total_not_b) # The number of times the A feature occurs given B / Number of events marked B\n",
        "        prob_of_feature_not_A_when_b = np.divide(self.count_of_feature_not_A_when_b, total_b) # The number of times the A feature occurs given B / Number of events marked B\n",
        "        prob_of_feature_not_A_when_not_b = np.divide(self.count_of_feature_not_A_when_not_b, total_not_b) # The number of times the A feature occurs given B / Number of events marked B\n",
        "\n",
        "        print(f\"prob_of_feature_A_when_b: {prob_of_feature_A_when_b}\")\n",
        "        print(f\"prob_of_feature_A_when_not_b: {prob_of_feature_A_when_not_b}\")\n",
        "        print(f\"prob_of_feature_not_A_when_b: {prob_of_feature_not_A_when_b}\")\n",
        "        print(f\"prob_of_feature_not_A_when_not_b: {prob_of_feature_not_A_when_not_b}\")\n",
        "\n",
        "\n",
        "        # # END: At this point, we have all the calculations required for what is necessary in the predict method\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "\n",
        "        import math\n",
        "\n",
        "        # The predict function accepts N events with M features to make a classification using the Naive Bayes implementation\n",
        "        # We want to multiply the existence of a feature (or lack thereof) by the probability that feature appears in the B (or not B) labeled training set\n",
        "\n",
        "        num_rows, num_cols = X.shape\n",
        "        y_predicted = np.full(num_rows, 0) \n",
        "\n",
        "        self.row_counter = 0\n",
        "        for row in X:\n",
        "            # print(f\"X: {row}\")\n",
        "\n",
        "            # Using the numpy multiply operator we can multiple each 'cell' by the corresponding 'cell'\n",
        "            prob_of_feature_A_when_b_weighted = np.multiply(row, prob_of_feature_A_when_b)\n",
        "            prob_of_feature_A_when_not_b_weighted = np.multiply(row, prob_of_feature_A_when_not_b)\n",
        "\n",
        "            # We need to swap out the 1s and 0s in the training set so we can multiply the 'not As' to get probabilities\n",
        "            print(f\"row: {row} row_mirrored: {abs(row-1)}\") # Checking to make sure this value does what I expect: YES\n",
        "            prob_of_feature_not_A_when_b_weighted = np.multiply(abs(row-1), prob_of_feature_not_A_when_b) # BIG THOUGHT REQUIRED HERE. NEED TO ASSERT A TRUE WHEN THE FEATURE IS FALSE\n",
        "            prob_of_feature_not_A_when_not_b_weighted = np.multiply(abs(row-1), prob_of_feature_not_A_when_not_b)\n",
        "\n",
        "            print(f\"\")\n",
        "\n",
        "\n",
        "            # With the probabilities of each feature we can now add the log() scores together\n",
        "            #   Note:   It's common for the probabilities for some of the features to come back zero\n",
        "            #           However the np.log function breaks when trying to take the log(0) since there's no exponent that will get the base value to zero\n",
        "            #           Since we no longer care about the order of the values, we can np.sort(), then np.trim_zeros to get rid of leading or trailing zeros\n",
        "            #           before we take the log()        \n",
        "   \n",
        "        \n",
        "            prob_of_feature_A_when_b_weighted_log = np.sum(np.log10(np.trim_zeros(np.sort(prob_of_feature_A_when_b_weighted))))\n",
        "            prob_of_feature_A_when_not_b_weighted_log = np.sum(np.log10(np.trim_zeros(np.sort(prob_of_feature_A_when_not_b_weighted))))\n",
        "            prob_of_feature_not_A_when_b_weighted_log = np.sum(np.log10(np.trim_zeros(np.sort(prob_of_feature_not_A_when_b_weighted))))\n",
        "            prob_of_feature_not_A_when_not_b_weighted_log = np.sum(np.log10(np.trim_zeros(np.sort(prob_of_feature_not_A_when_not_b_weighted))))\n",
        "\n",
        "            prob_of_B_given_A = (prob_of_feature_A_when_b_weighted_log + prob_of_feature_not_A_when_b_weighted_log + math.log10(p_of_b))\n",
        "            prob_of_not_B_given_A =  (prob_of_feature_A_when_not_b_weighted_log + prob_of_feature_not_A_when_not_b_weighted_log + math.log10(p_of_not_b)) # ** is the operator for raising a value to that power\n",
        "\n",
        "            print(f\"Row {self.row_counter}: prob_of_B_given_A: {prob_of_B_given_A} vs prob_of_not_B_given_A: {prob_of_not_B_given_A}\")\n",
        "\n",
        "            if prob_of_B_given_A >= prob_of_not_B_given_A: \n",
        "                y_predicted[self.row_counter] = 1\n",
        "            else:\n",
        "                y_predicted[self.row_counter] = -1\n",
        "\n",
        "            self.row_counter += 1\n",
        "\n",
        "        # print(f\"y_predicted: {y_predicted}\")\n",
        "        return np.array(y_predicted) # For a long time I was returning self\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define pipelines\n",
        "\n",
        "from sklearn.pipeline import Pipeline # For setting up pipeline\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "NBClassifier_pipe = Pipeline([\n",
        "# ('scaler', StandardScaler()), # Not necessary for this exercise\n",
        "# ('selector', VarianceThreshold()), # Not necessary for this exercise\n",
        "('imputer', SimpleImputer(strategy='most_frequent')), # Impute the values when missing values\n",
        "('classifier', BinaryNBClassifier())\n",
        "])\n",
        "\n",
        "CategoricalNB_pipe = Pipeline([\n",
        "# ('scaler', StandardScaler()), # Not necessary for this exercise\n",
        "# ('selector', VarianceThreshold()), # Not necessary for this exercise\n",
        "('imputer', SimpleImputer(strategy='most_frequent')), # Impute the values when missing values\n",
        "('classifier', CategoricalNB())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|dataset\t|# of instances\t|# of features\t|Your NB Training Time\t|Your NB Test Time\t|Your NB Accuracy\t|sklearn CategoricalNB Training Time\t|sklearn Categorical NB Test Time\t|sklearn CategoricalNB Accuracy\t|\n",
            "p_of_b: 0.3 p_of_not_b: 0.7\n",
            "count_of_feature_A_when_b: [2 2 2 ... 1 3 1]\n",
            "count_of_feature_A_when_not_b: [3 5 1 ... 3 6 5]\n",
            "count_of_feature_not_A_when_b: [1 1 1 ... 2 0 2]\n",
            "count_of_feature_not_A_when_not_b: [4 2 6 ... 4 1 2]\n",
            "prob_of_feature_A_when_b: [0.66666667 0.66666667 0.66666667 ... 0.33333333 1.         0.33333333]\n",
            "prob_of_feature_A_when_not_b: [0.42857143 0.71428571 0.14285714 ... 0.42857143 0.85714286 0.71428571]\n",
            "prob_of_feature_not_A_when_b: [0.33333333 0.33333333 0.33333333 ... 0.66666667 0.         0.66666667]\n",
            "prob_of_feature_not_A_when_not_b: [0.57142857 0.28571429 0.85714286 ... 0.57142857 0.14285714 0.28571429]\n",
            "row: [1 0 1 ... 1 1 0] row_mirrored: [0 1 0 ... 0 0 1]\n",
            "\n",
            "Row 0: prob_of_B_given_A: -1739.7716153227095 vs prob_of_not_B_given_A: -3123.1695395818647\n",
            "row: [0 1 0 ... 0 0 0] row_mirrored: [1 0 1 ... 1 1 1]\n",
            "\n",
            "Row 1: prob_of_B_given_A: -1919.1854927384422 vs prob_of_not_B_given_A: -2730.858742789264\n",
            "row: [1 1 0 ... 0 1 1] row_mirrored: [0 0 1 ... 1 0 0]\n",
            "\n",
            "Row 2: prob_of_B_given_A: -1739.1695553313814 vs prob_of_not_B_given_A: -3155.410514069943\n",
            "row: [0 1 1 ... 1 1 1] row_mirrored: [1 0 0 ... 0 0 0]\n",
            "\n",
            "Row 3: prob_of_B_given_A: -1908.9504728858667 vs prob_of_not_B_given_A: -2680.6464338317187\n",
            "row: [0 1 1 ... 0 1 0] row_mirrored: [1 0 0 ... 1 0 1]\n",
            "\n",
            "Row 4: prob_of_B_given_A: -1736.4602853704055 vs prob_of_not_B_given_A: -3156.9119398987295\n",
            "row: [1 1 0 ... 0 1 1] row_mirrored: [0 0 1 ... 1 0 0]\n",
            "\n",
            "Row 5: prob_of_B_given_A: -2061.572680687505 vs prob_of_not_B_given_A: -2366.528116834876\n",
            "row: [1 1 0 ... 1 1 1] row_mirrored: [0 0 1 ... 0 0 0]\n",
            "\n",
            "Row 6: prob_of_B_given_A: -2064.2819506484807 vs prob_of_not_B_given_A: -2348.203399583332\n",
            "row: [0 1 0 ... 0 1 1] row_mirrored: [1 0 1 ... 1 0 0]\n",
            "\n",
            "Row 7: prob_of_B_given_A: -2055.5520807742255 vs prob_of_not_B_given_A: -2382.249083723993\n",
            "row: [0 0 0 ... 0 1 0] row_mirrored: [1 1 1 ... 1 0 1]\n",
            "\n",
            "Row 8: prob_of_B_given_A: -2064.281950648481 vs prob_of_not_B_given_A: -2376.6671335388114\n",
            "row: [1 0 0 ... 1 1 1] row_mirrored: [0 1 1 ... 0 0 0]\n",
            "\n",
            "Row 9: prob_of_B_given_A: -2075.1190304923844 vs prob_of_not_B_given_A: -2361.1036222774214\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n",
            "|test1_4\t|10\t\t|10000\t\t|0.99252\t\t|0.017295\t\t|0.3\t\t\t|1.185314\t\t\t\t|0.011292\t\t\t\t|1.0\t\t\t\t|\n",
            "|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\n"
          ]
        }
      ],
      "source": [
        "# Loop through files in directory:\n",
        "\n",
        "# import required modules\n",
        "import os\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "# def evaluate_results(y_train,y_pred):\n",
        "\n",
        "# assign directory\n",
        "directory = 'Datasets for Assignment 2'\n",
        "\n",
        "# print header\n",
        "print(\"|dataset\\t|# of instances\\t|# of features\\t|Your NB Training Time\\t|Your NB Test Time\\t|Your NB Accuracy\\t|sklearn CategoricalNB Training Time\\t|sklearn Categorical NB Test Time\\t|sklearn CategoricalNB Accuracy\\t|\")\n",
        " \n",
        "# iterate over files in directory\n",
        "for filename in sorted(os.listdir(directory)):    \n",
        "    if not filename.startswith('.') and filename == \"test1_4.csv\": # This command excludes the .DS_Store common on Mac OS  : and filename == \"test1_4.csv\"\n",
        "        f = os.path.join(directory, filename)\n",
        "        # checking if it is a file\n",
        "        if os.path.isfile(f):\n",
        "            # print(f)\n",
        "            df = pd.DataFrame()\n",
        "            df = pd.read_csv(f,)\n",
        "            df.info\n",
        "            \n",
        "            # Prepare the data\n",
        "\n",
        "            #   The values for the Events are up to the last column\n",
        "            #   X = np.zeros(1) # Reset the array\n",
        "            X = df.iloc[:,:-1].values # The values are everything but the last column\n",
        "            \n",
        "            #   The values for the Classification are in the last column\n",
        "            y = df.iloc[:,-1:].values\n",
        "\n",
        "            # Splitting the dataset into the Training set and Test set\n",
        "            # from sklearn.model_selection import train_test_split\n",
        "            # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)\n",
        "\n",
        "            # However for this particular exercise, the instruction is to use all the samples for training and testing\n",
        "            X_train = X\n",
        "            y_train = y\n",
        "\n",
        "            X_test = X\n",
        "            y_test = y\n",
        "\n",
        "            num_instances, num_features = np.shape(X_train)\n",
        "\n",
        "            # Call pipelines\n",
        "            CategoricalNB_fit_start =  time.time() # Returns Unix epoch time\n",
        "            CategoricalNB_pipe.fit(X_train, y_train.ravel())\n",
        "            CategoricalNB_fit_end =  time.time() # Returns Unix epoch time\n",
        "            CategoricalNB_fit_seconds_elapsed = round(CategoricalNB_fit_end - CategoricalNB_fit_start, 6)\n",
        "\n",
        "            CategoricalNB_predict = CategoricalNB_pipe.predict(X_train)\n",
        "            CategoricalNB_predict_end =  time.time() # Returns Unix epoch time\n",
        "            CategoricalNB_predict_seconds_elapsed = round(CategoricalNB_predict_end - CategoricalNB_fit_end, 6)\n",
        "            CategoricalNB_accuracy =  accuracy_score(y_train, CategoricalNB_predict)\n",
        "\n",
        "\n",
        "            NBClassifier_fit_start =  time.time() # Returns Unix epoch time\n",
        "            NBClassifier_pipe.fit(X_train, y_train)\n",
        "            NBClassifier_fit_end =  time.time() # Returns Unix epoch time\n",
        "            NBClassifier_fit_seconds_elapsed = round(NBClassifier_fit_end - NBClassifier_fit_start, 6)\n",
        "\n",
        "            NBClassifier_predict = NBClassifier_pipe.predict(X_train)\n",
        "            NBClassifier_predict_end =  time.time() # Returns Unix epoch time\n",
        "            NBClassifier_predict_seconds_elapsed = round(NBClassifier_predict_end - NBClassifier_fit_end, 6)\n",
        "            NBClassifier_accuracy =  accuracy_score(y_train, NBClassifier_predict)\n",
        "            # print(f\"NBClassifier accuracy: {NBClassifier_accuracy}\")\n",
        "            \n",
        "            print(\"|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\")\n",
        "            print(f\"|{filename[:-4]}\\t|{num_instances}\\t\\t|{num_features}\\t\\t|{NBClassifier_fit_seconds_elapsed}\\t\\t|{NBClassifier_predict_seconds_elapsed}\\t\\t|{NBClassifier_accuracy}\\t\\t\\t|{CategoricalNB_fit_seconds_elapsed}\\t\\t\\t\\t|{CategoricalNB_predict_seconds_elapsed}\\t\\t\\t\\t|{CategoricalNB_accuracy}\\t\\t\\t\\t|\")\n",
        "print(\"|---------------|---------------|---------------|-----------------------|-----------------------|-----------------------|---------------------------------------|---------------------------------------|-------------------------------|\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/m0/ggccpqsn2kj_43nbhzzcn79m0000gp/T/ipykernel_39126/3988292716.py:2: RuntimeWarning: divide by zero encountered in log10\n",
            "  np.log10([.1, 0, .01, .001])\n",
            "/var/folders/m0/ggccpqsn2kj_43nbhzzcn79m0000gp/T/ipykernel_39126/3988292716.py:3: RuntimeWarning: divide by zero encountered in log10\n",
            "  np.log10(np.sort([.1, 0, .01, .001]))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1e-06"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check np operations:\n",
        "np.log10([.1, 0, .01, .001])\n",
        "np.log10(np.sort([.1, 0, .01, .001]))\n",
        "np.log10(np.trim_zeros(np.sort([.1, 0, .01, .001])))\n",
        "np.sum(np.log10(np.trim_zeros(np.sort([.1, 0, .01, .001]))))\n",
        "10**np.sum(np.log10(np.trim_zeros(np.sort([.1, 0, .01, .001]))))\n",
        ".1 * .01 * .001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_train:\t\t [[ 1]\n",
            " [-1]\n",
            " [ 1]\n",
            " [-1]\n",
            " [ 1]\n",
            " [-1]\n",
            " [-1]\n",
            " [-1]\n",
            " [-1]\n",
            " [-1]]\n",
            "NBClassifier_predict:\t [1 1 1 1 1 1 1 1 1 1]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 10",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/Users/robchristiansen/Documents/Code/Learning/WeberState/CS 6600 (Machine Learning)/Assignments/Assignment2.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment2.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNBClassifier_predict:\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mNBClassifier_predict\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment2.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#lets see the actual and predicted value side by side\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment2.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y_compare \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvstack((y_train,NBClassifier_predict))\u001b[39m.\u001b[39mT\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment2.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#actual value on the left side and predicted value on the right hand side\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment2.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#printing the top 5 values\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment2.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y_compare[:]\n",
            "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/numpy/core/shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    295\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[0;32m--> 296\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n",
            "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 10"
          ]
        }
      ],
      "source": [
        "print(f\"y_train:\\t\\t {y_train}\")\n",
        "print(f\"NBClassifier_predict:\\t {NBClassifier_predict}\")\n",
        "\n",
        "#lets see the actual and predicted value side by side\n",
        "y_compare = np.vstack((y_train,NBClassifier_predict)).T\n",
        "#actual value on the left side and predicted value on the right hand side\n",
        "#printing the top 5 values\n",
        "y_compare[:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv24NS1RCpjT"
      },
      "source": [
        "Now you will train and test your Binary Naive Bayes classifier on a few different datasets.  The datasets can be downloaded from canvas.  They are linked in the assignment description.  For this part of the assignment we will not be splitting the data into training, validation and test data sets.  Instead you should use the entire dataset for training and the entire dataset for testing.  You will need to complete the following table (you can just output the results in this format you don't need to copy them into the text field).\n",
        "\n",
        "|dataset|# of instances|# of features | Your NB Training Time | Your NB Test Time | Your NB Accuracy | sklearn CategoricalNB Training Time | sklearn Categorical NB Test Time | sklearn CategoricalNB Accuracy|\n",
        "|-----------|------------|-------------|------------------|-------------------|-------------------------|---------------------------------|------------------------|----------------------------------|\n",
        "test1_1 |\n",
        "test1_2 |\n",
        "test1_4 |\n",
        "test1_5 |\n",
        "test2_1 |\n",
        "test2_2 |\n",
        "test2_4 |\n",
        "test2_5 |\n",
        "test4_1 |\n",
        "test4_2 |\n",
        "test4_4 |\n",
        "test4_5 |\n",
        "test5_1 |\n",
        "test5_2 |\n",
        "test5_4 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "n6x9Ol9tE0OX"
      },
      "outputs": [],
      "source": [
        "#Train and test your BinaryNBClassifier and the sklearn CategoricalNBClassifier on the datasets from canvas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzzilfSNFGvY"
      },
      "source": [
        "The next step for this assignment is split the vote dataset (also found on canvas) into a *train/test split* (use 20% of the data for testing).  Train both algorithms on the training data using *cross-fold validation* and then report the accuracy, f1-score, mcc and informedness results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi8VaK4V1z_E"
      },
      "outputs": [],
      "source": [
        "#Split the vote dataset\n",
        "#Use cross-validatation to compare BinaryNBClassifier against CategoricalNBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFP5ttuS2AtP"
      },
      "source": [
        "Finally, choose the algorithm that performed the best on the cross-validation, train it on all the training data and test on the test data.  Report the accuracy, f1-score, mcc and informedness results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UquA9oi22X-Q"
      },
      "outputs": [],
      "source": [
        "#Final Generalization test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell remains as a reminder of a LOT of work I did to try to maintain the words with their 'labels'. \n",
        "\n",
        "#Spliting the dataset in independent and dependent variables\n",
        "# X = df.iloc[:,:-1].to_dict('list') # The idea here is to capture all the columns except the last one as X\n",
        "# y = df['Class'].to_dict('records')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
