{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, balanced_accuracy_score # balanced_accuracy_score with adjusted=True is Informedness\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df_train = pd.read_csv('Datasets for Assignment 3/census-income.csv')\n",
    "df_test = pd.read_csv('Datasets for Assignment 3/census-income-test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When to One-Hot Encode vs Label Encode?\n",
    "\n",
    "```To prevent biases from being introduced, One-Hot Encoding is preferable for nominal data (where there is no inherent order among categories). Label encoding, however, might be more appropriate for ordinal data (where categories naturally have an order)```\n",
    "\n",
    "So we should one-hot encode columns like class of worker, state of residence, etc. After reviewing the column descriptions I decided to one-hot encode all the following columns:\n",
    "\n",
    "'ACLSWKR', 'ADTIND', 'ADTOCC', 'AMARITL', 'AMJIND', 'AMJOCC', 'ARACE', 'AREORGN', 'ASEX', 'AUNMEM', 'AUNTYPE', 'AWKSTAT', 'FILESTAT', 'GRINREG', 'GRINST', 'HHDFMX', 'HHDREL', 'MIGMTR1', 'MIGMTR3', 'MIGMTR4', 'PARENT', 'PEFNTVTY', 'PEMNTVTY', 'PENATVTY', 'PRCITSHP', 'SEOTR'\n",
    "\n",
    "**https://www.geeksforgeeks.org/ml-one-hot-encoding-of-datasets-in-python/**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(df_train, df_test, columns_to_one_hot_encode, columns_to_label_encode, columns_to_scale):\n",
    "\n",
    "    def OneHotEncode (df, columns_to_one_hot_encode):\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        onehotencode = OneHotEncoder()      \n",
    "\n",
    "        for item in columns_to_one_hot_encode:\n",
    "            df[item] = df[item].astype('category') # Must convert the strings to category numbers for One Hot to work\n",
    "            df[item + '_new'] = df[item].cat.codes # Rob: Need to research this more\n",
    "            # print(f\" Column: {item}\")\n",
    "            # print(df[item + '_new'])\n",
    "\n",
    "        OneHot_df = pd.DataFrame(onehotencode.fit_transform(df[columns_to_one_hot_encode]).toarray())\n",
    "\n",
    "        PostOneHot_df = df.join(OneHot_df) # Appends the OneHot_df to the original dataframe to create a new one\n",
    "        PostOneHot_df[:-100] # Check results from the One Hot Encoding\n",
    "        PostOneHot_df = PostOneHot_df.drop(columns=columns_to_one_hot_encode)\n",
    "        df = PostOneHot_df\n",
    "        return df\n",
    "\n",
    "    def StripSpaces (df):\n",
    "        # I noticed some of the columns get imported with leading spaces. I want to strip() these right away\n",
    "        for column in df.select_dtypes(include=object): # Only review the columns with a str datatype\n",
    "            df[column] = df[column].apply(lambda x: x.strip())\n",
    "        return df\n",
    "    \n",
    "    def PreLabelEncode(df):\n",
    "        #   Before label encoding we want to apply some value judgements to the data to give the resulting labels some ranking\n",
    "        #   education\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"Children\", \"0\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"Less than 1st grade\", \"1\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"1st 2nd 3rd or 4th grade\", \"2\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"5th or 6th grade\", \"3\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"7th and 8th grade\", \"4\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"9th grade\", \"5\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"10th grade\", \"6\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"11th grade\", \"7\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"12th grade no diploma\", \"8\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"High school graduate\", \"9\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"Some college but no degree\", \"10\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"Associates degree-occup /vocational\", \"11\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"Associates degree-academic program\", \"12\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"Bachelors degree(BA AB BS)\", \"13\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"Masters degree(MA MS MEng MEd MSW MBA)\", \"14\"))\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"Doctorate degree(PhD EdD)\", \"15\")) # Sorry Dr. Feuz, but the professional doctorates have you beat in earning potential\n",
    "        df[\"AHGA\"] = df[\"AHGA\"].apply(lambda x: x.replace(\"Prof school degree (MD DDS DVM LLB JD)\", \"16\"))\n",
    "\n",
    "        #   enrolled in edu inst last wk\n",
    "        df[\"AHSCOL\"] = df[\"AHSCOL\"].apply(lambda x: x.replace(\"Not in universe\", \"0\"))\n",
    "        df[\"AHSCOL\"] = df[\"AHSCOL\"].apply(lambda x: x.replace(\"High school\", \"1\"))\n",
    "        df[\"AHSCOL\"] = df[\"AHSCOL\"].apply(lambda x: x.replace(\"College or university\", \"2\"))\n",
    "\n",
    "        #   live in this house 1 year ago\n",
    "        df[\"MIGSAME\"] = df[\"MIGSAME\"].apply(lambda x: x.replace(\"Not in universe under 1 year old\", \"0\"))\n",
    "        df[\"MIGSAME\"] = df[\"MIGSAME\"].apply(lambda x: x.replace(\"No\", \"1\"))\n",
    "        df[\"MIGSAME\"] = df[\"MIGSAME\"].apply(lambda x: x.replace(\"Yes\", \"2\"))\n",
    "\n",
    "        #   migration prev res in sunbelt\n",
    "        df[\"MIGSUN\"] = df[\"MIGSUN\"].apply(lambda x: x.replace(\"?\", \"0\"))\n",
    "        df[\"MIGSUN\"] = df[\"MIGSUN\"].apply(lambda x: x.replace(\"Not in universe\", \"1\"))\n",
    "        df[\"MIGSUN\"] = df[\"MIGSUN\"].apply(lambda x: x.replace(\"No\", \"1\"))\n",
    "        df[\"MIGSUN\"] = df[\"MIGSUN\"].apply(lambda x: x.replace(\"Yes\", \"2\"))\n",
    "\n",
    "        #   fill inc questionnaire for veteran's admin\n",
    "        df[\"VETQVA\"] = df[\"VETQVA\"].apply(lambda x: x.replace(\"Not in universe\", \"0\"))\n",
    "        df[\"VETQVA\"] = df[\"VETQVA\"].apply(lambda x: x.replace(\"No\", \"1\"))\n",
    "        df[\"VETQVA\"] = df[\"VETQVA\"].apply(lambda x: x.replace(\"Yes\", \"2\"))\n",
    "\n",
    "        return df\n",
    "\n",
    "    def LabelEncode(df, columns_to_label_encode):\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        LabelEncode = LabelEncoder()\n",
    "\n",
    "        for item in columns_to_label_encode:\n",
    "            df[item]= LabelEncode.fit_transform(df[item])\n",
    "            print(f\"Post Label Encoding for {item}: {df[item].unique()}\")\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def StandardScale(df, columns_to_scale):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        scaled_columns = scaler.fit_transform(df[columns_to_scale])\n",
    "        df[columns_to_scale] = scaled_columns\n",
    "\n",
    "        return df\n",
    "    \n",
    "    df_train = StripSpaces(df_train)\n",
    "    df_train = OneHotEncode(df_train, columns_to_one_hot_encode)\n",
    "    df_train = PreLabelEncode(df_train)\n",
    "    df_train = LabelEncode(df_train, columns_to_label_encode)\n",
    "    df_train = StandardScale(df_train, columns_to_scale)\n",
    "\n",
    "    print(f\"df_test before processing: {df_test.info()}\")    \n",
    "    df_test = StripSpaces(df_test)\n",
    "    df_test = OneHotEncode(df_test, columns_to_one_hot_encode)\n",
    "    df_test = PreLabelEncode(df_test)\n",
    "    df_test = LabelEncode(df_test, columns_to_label_encode)\n",
    "    df_test = StandardScale(df_test, columns_to_scale)    \n",
    "    print(f\"df_test after processing: {df_test.info()}\")    \n",
    "    \n",
    "    return(df_train, df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's label encode some of the columns, but first let's update the columns so they have an inherent rank order\n",
    "\n",
    "Reference: https://www.geeksforgeeks.org/ml-label-encoding-of-datasets-in-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15095836,  9.        , -0.20155813, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.41961503,  3.        , -0.20155813, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.46098168,  0.        , -0.20155813, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.47590721, 11.        , -0.20155813, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.20725054,  5.        , -0.20155813, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.44946561, 12.        , -0.20155813, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell helps view the values we want to label encode\n",
    "df_test['VETQVA'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ACLSWKR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ACLSWKR'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/robchristiansen/Documents/Code/Learning/WeberState/CS 6600 (Machine Learning)/Assignments/Assignment3.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m columns_to_label_encode \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAHGA\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mAHSCOL\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mMIGSAME\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mMIGSUN\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mVETQVA\u001b[39m\u001b[39m'\u001b[39m,]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m columns_to_scale \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAAGE\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mAHRSPAY\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mCAPGAIN\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mCAPLOSS\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mDIVVAL\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mNOEMP\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mWKSWORK\u001b[39m\u001b[39m'\u001b[39m,]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_train, df_test \u001b[39m=\u001b[39m Preprocessing(df_train, df_test, columns_to_one_hot_encode, columns_to_label_encode, columns_to_scale)\n",
      "\u001b[1;32m/Users/robchristiansen/Documents/Code/Learning/WeberState/CS 6600 (Machine Learning)/Assignments/Assignment3.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m df_train \u001b[39m=\u001b[39m StripSpaces(df_train)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m df_train \u001b[39m=\u001b[39m OneHotEncode(df_train, columns_to_one_hot_encode)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m df_train \u001b[39m=\u001b[39m PreLabelEncode(df_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m df_train \u001b[39m=\u001b[39m LabelEncode(df_train, columns_to_label_encode)\n",
      "\u001b[1;32m/Users/robchristiansen/Documents/Code/Learning/WeberState/CS 6600 (Machine Learning)/Assignments/Assignment3.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m onehotencode \u001b[39m=\u001b[39m OneHotEncoder()      \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m columns_to_one_hot_encode:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     df[item] \u001b[39m=\u001b[39m df[item]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# Must convert the strings to category numbers for One Hot to work\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     df[item \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_new\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[item]\u001b[39m.\u001b[39mcat\u001b[39m.\u001b[39mcodes \u001b[39m# Rob: Need to research this more\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# print(f\" Column: {item}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robchristiansen/Documents/Code/Learning/WeberState/CS%206600%20%28Machine%20Learning%29/Assignments/Assignment3.ipynb#X42sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# print(df[item + '_new'])\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ACLSWKR'"
     ]
    }
   ],
   "source": [
    "columns_to_one_hot_encode = ['ACLSWKR', 'ADTIND', 'ADTOCC', 'AMARITL', 'AMJIND', 'AMJOCC', 'ARACE', 'AREORGN', 'ASEX', 'AUNMEM', 'AUNTYPE', 'AWKSTAT', 'FILESTAT', 'GRINREG', 'GRINST', 'HHDFMX', 'HHDREL', 'MIGMTR1', 'MIGMTR3', 'MIGMTR4', 'PARENT', 'PEFNTVTY', 'PEMNTVTY', 'PENATVTY', 'PRCITSHP', 'SEOTR']\n",
    "columns_to_label_encode = ['AHGA','AHSCOL','MIGSAME','MIGSUN','VETQVA',]\n",
    "columns_to_scale = ['AAGE','AHRSPAY','CAPGAIN','CAPLOSS','DIVVAL','NOEMP','WKSWORK',]\n",
    "\n",
    "df_train, df_test = Preprocessing(df_train, df_test, columns_to_one_hot_encode, columns_to_label_encode, columns_to_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a Kaggle page showing the best categorical classifiers for a given data set:\n",
    "* https://www.kaggle.com/code/jeffd23/10-classifier-showdown-in-scikit-learn\n",
    "* Comment about grid search: https://www.kaggle.com/code/jeffd23/10-classifier-showdown-in-scikit-learn/comments#135499\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99762 entries, 0 to 99761\n",
      "Columns: 506 entries, AAGE to 466\n",
      "dtypes: float64(474), int64(6), int8(26)\n",
      "memory usage: 367.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.info()\n",
    "\n",
    "X_train = df_train.drop(columns='CLASS').values # Include ALL columns except CLASS\n",
    "y_train = df_train['CLASS'].values # Only include Class\n",
    "\n",
    "# Would normally run the following line, but CLASS isn't in the test data\n",
    "# X_test = df_test.drop(columns='CLASS').values # Include ALL columns except CLASS\n",
    "X_test = df_test.values # Include ALL columns except CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, train_predictions)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    \n",
    "    train_predictions = clf.predict_proba(X_test)\n",
    "    ll = log_loss(y_test, train_predictions)\n",
    "    print(\"Log Loss: {}\".format(ll))\n",
    "    \n",
    "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:-100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would be good to write code that would loop through all the columns and print out the uniques to add decisions about one-hot vs label encoding vs scaling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that takes one column and generates 9 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
