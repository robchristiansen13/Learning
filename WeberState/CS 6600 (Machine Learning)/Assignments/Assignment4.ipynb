{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6GaaBjFPmns"
      },
      "source": [
        "For this assignment you will be implementing your own verision of the perceptron algorithm.  Similar to the Naive Bayes assignment your Percptron class should be built to be compatible with the sklearn framework.  You can use the sklearn library and other python libraries to help with your implementation but you must implement the actual percpetron algorithm using your own code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import required modules\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "** FOR FUTURE REFERENCE: YOU MUST, MUST FOLLOW THE TEMPLATE FOR WHAT NEEDS TO BE IN THE FIT AND PREDICT METHODS AT:\n",
        "\n",
        "https://scikit-learn.org/stable/developers/develop.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SLRLL7L0PYJ0"
      },
      "outputs": [],
      "source": [
        "#TODO: put your perceptron implemenation here\n",
        "\n",
        "#initial imports that you may find useful\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "class custom_perceptron(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, alpha=0.1, epochs=1):\n",
        "        self.alpha = alpha\n",
        "        self.epochs = epochs\n",
        "                 \n",
        "    def predict(self, X):\n",
        "        def sigmoid(x):\n",
        "            return 1 / (1 + np.exp(-x))\n",
        "\n",
        "        # Check if fit has been called\n",
        "        check_is_fitted(self)\n",
        "        \n",
        "        # Input validation\n",
        "        X = check_array(X)\n",
        "\n",
        "        y_hat = np.zeros(len(X))\n",
        "\n",
        "        for i, row in enumerate(X):                      # Iterate through both X and y together. i is the counter, row is X[i]\n",
        "            # print(f\"predict.enumerate.row: {row}\")\n",
        "            a = sigmoid(np.sum(np.dot(weights,row)))\n",
        "            # print(f\"a: {a} from sigmoid(sum({weights} product {row}))\")\n",
        "\n",
        "            if a >= 0.5:\n",
        "                # print(f\"Class: 1\")\n",
        "                y_hat[i] = 1\n",
        "            else:\n",
        "                # print(f\"Class: -1\")\n",
        "                y_hat[i] = -1\n",
        "        \n",
        "        return y_hat\n",
        "    \n",
        "    def train_weights(self, X, y, y_predicted, weights, alpha):\n",
        "        X_rows, X_columns = X.shape\n",
        "        weights_update = np.zeros((X_columns))\n",
        "\n",
        "        for i, row in enumerate(zip(y, y_predicted, X)):\n",
        "            if row[0] != int(row[1]):\n",
        "                # Update the weights for each misclassified example\n",
        "                weights_update += alpha * row[2] * (row[0] - row[1])\n",
        "\n",
        "        # Apply the accumulated weight updates\n",
        "        weights += weights_update\n",
        "        return weights\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "\n",
        "        # STEP 0: Check the parameters\n",
        "        # Check that X and y have correct shape\n",
        "        X, y = check_X_y(X, y)\n",
        "\n",
        "        # Store the classes seen during fit\n",
        "        self.classes_ = unique_labels(y)\n",
        "        \n",
        "        # STEP 1: Initialize the weights of the parameters\n",
        "        X_rows, X_columns = X.shape\n",
        "        # print(f\"X shape: {X_rows}, {X_columns}\")\n",
        "        global weights\n",
        "        weights = np.random.randn(X_columns) # Create an array with the number of parameters as X with the random numbers normally distributed (fewer outliers)\n",
        "        # print(f\"Initial random weights: {weights}\")\n",
        "\n",
        "        # STEP 2: Apply the weights to the Nth instance\n",
        "        \n",
        "        epoch = 1\n",
        "        while epoch <= self.epochs:\n",
        "            # print(f\"\\n\\nEpoch: {epoch}\")\n",
        "            y_hat = np.zeros(len(X))\n",
        "            y_hat = custom_perceptron.predict(self, X)\n",
        "            # print(f\"len(X): {len(X)} len(y): {len(y)} len(y_hat): {len(y_hat)}\")\n",
        "            # print(f\"y_hat: {y_hat}\")\n",
        "\n",
        "            # for i, row in enumerate(zip(y, y_hat)):                    # Iterate through both X and y together. i is the counter, row is X[i]\n",
        "            weights = self.train_weights(X, y, y_hat, weights, self.alpha)\n",
        "            epoch += 1\n",
        "        \n",
        "        return self\n",
        "            \n",
        "    def classes_(self):\n",
        "        if self.estimator:\n",
        "            return self.estimator.classes_\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(X): 4 len(y): 4 len(y_hat): 4\n",
            "y_hat: [1. 1. 1. 1.]\n",
            "[-1. -1. -1. -1.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create some sample data and labels\n",
        "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
        "y = np.array([1, 1, -1, -1])\n",
        "\n",
        "# Create and train a perceptron model\n",
        "perceptron = custom_perceptron(alpha=0.1, epochs=1)\n",
        "perceptron.fit(X, y)\n",
        "\n",
        "# Use the predict method to make predictions on the same data\n",
        "predictions = perceptron.predict(X)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pdClma2RGpf"
      },
      "source": [
        "Split the diabetes data into and 80/20 train/test split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-VnlgTV_SodE"
      },
      "outputs": [],
      "source": [
        "#TODO: split the diabetes data into training/test data\n",
        "\n",
        "df = pd.read_csv('Datasets for Assignment 4/diabetes.csv')\n",
        "X = df.drop(columns='class')\n",
        "y = df['class']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGgFkk-zS6iu"
      },
      "source": [
        "Using the diabetes training data with k-fold cross-validation (you choose the value for k) plot your perceptron's cross-validation accuracy and MCC as a function of the number of training epochs.  Use a learning rate of 0.10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O3e2jeSrUWZ_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(X): 491 len(y): 491 len(y_hat): 491\n",
            "y_hat: [ 1. -1. -1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.\n",
            "  1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1. -1.\n",
            " -1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1.\n",
            "  1. -1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
            " -1. -1.  1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1.\n",
            "  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1. -1.\n",
            "  1. -1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1.  1.\n",
            "  1. -1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1.  1. -1. -1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1.\n",
            " -1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1.\n",
            "  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1.\n",
            " -1. -1.  1. -1.  1. -1. -1.  1.  1. -1.  1. -1. -1. -1. -1.  1.  1.  1.\n",
            " -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.\n",
            "  1. -1.  1. -1.  1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1.\n",
            "  1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1. -1.  1.\n",
            "  1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1.\n",
            " -1.  1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1. -1.\n",
            "  1.  1. -1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1. -1.  1.\n",
            "  1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1. -1. -1.\n",
            " -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
            " -1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1.  1.\n",
            "  1. -1.  1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1.  1.\n",
            " -1. -1. -1.  1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
            "  1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
            " -1. -1. -1.  1.  1.  1. -1. -1. -1. -1.  1. -1. -1.  1.  1. -1.  1. -1.\n",
            "  1. -1. -1.  1. -1.]\n",
            "len(X): 491 len(y): 491 len(y_hat): 491\n",
            "y_hat: [-1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.  1.\n",
            " -1.  1.  1.  1. -1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1. -1.  1.\n",
            "  1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1.\n",
            " -1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1. -1.\n",
            "  1.  1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1.\n",
            " -1. -1.  1. -1. -1.  1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1.  1. -1.\n",
            " -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.\n",
            "  1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1.\n",
            " -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1.\n",
            "  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1.  1.\n",
            " -1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1. -1.  1.  1.\n",
            "  1. -1.  1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1.\n",
            "  1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1.  1.\n",
            " -1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1. -1.\n",
            "  1. -1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1.\n",
            " -1. -1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1.  1.\n",
            "  1. -1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1. -1.\n",
            "  1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1.  1. -1.  1. -1. -1.  1.\n",
            " -1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1.\n",
            " -1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
            "  1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.\n",
            " -1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1.\n",
            "  1. -1.  1.  1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1. -1.\n",
            "  1.  1. -1. -1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1. -1.  1.\n",
            "  1. -1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1.\n",
            "  1.  1.  1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1. -1.\n",
            " -1.  1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
            " -1. -1.  1. -1. -1.]\n",
            "len(X): 491 len(y): 491 len(y_hat): 491\n",
            "y_hat: [-1.  1. -1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1.\n",
            " -1.  1. -1. -1. -1. -1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1.  1.  1.\n",
            " -1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1.  1.\n",
            "  1.  1.  1. -1. -1. -1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1. -1.\n",
            "  1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1.\n",
            "  1. -1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1. -1.\n",
            "  1.  1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1. -1.\n",
            "  1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1. -1. -1.\n",
            " -1.  1. -1. -1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
            " -1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1.  1.  1. -1. -1.  1. -1. -1.\n",
            "  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1.\n",
            "  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1.\n",
            " -1. -1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1.\n",
            " -1. -1. -1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1. -1. -1.  1.\n",
            " -1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.\n",
            " -1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1.\n",
            "  1.  1. -1. -1.  1. -1.  1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1.  1.\n",
            " -1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.\n",
            "  1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1.\n",
            " -1.  1.  1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.\n",
            " -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1. -1.\n",
            " -1. -1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1.\n",
            " -1.  1. -1. -1. -1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1. -1.\n",
            "  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1.\n",
            "  1.  1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.\n",
            " -1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
            "  1.  1. -1. -1.  1.]\n",
            "len(X): 491 len(y): 491 len(y_hat): 491\n",
            "y_hat: [ 1. -1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1.  1.\n",
            "  1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1.  1.  1.  1.\n",
            "  1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1.\n",
            "  1. -1.  1.  1.  1. -1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1. -1. -1.\n",
            "  1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1. -1.  1.\n",
            "  1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.\n",
            " -1. -1. -1.  1.  1.  1. -1. -1. -1. -1.  1. -1.  1.  1.  1. -1. -1.  1.\n",
            " -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1.  1.  1. -1.  1.  1.\n",
            "  1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1. -1.  1. -1. -1. -1. -1.\n",
            "  1. -1.  1. -1.  1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1.\n",
            " -1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1.\n",
            "  1.  1.  1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1. -1. -1.\n",
            "  1. -1.  1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1.\n",
            " -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.\n",
            "  1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1. -1. -1.\n",
            "  1. -1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1.  1. -1.\n",
            "  1. -1. -1.  1. -1. -1.  1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1. -1.\n",
            "  1. -1.  1. -1. -1.  1.  1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1. -1.\n",
            " -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.\n",
            "  1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1.  1. -1. -1.\n",
            " -1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.\n",
            "  1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1.\n",
            " -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1.\n",
            " -1. -1.  1.  1. -1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1.\n",
            "  1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1.\n",
            " -1. -1. -1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1.  1.\n",
            " -1.  1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1. -1. -1. -1.\n",
            " -1. -1.  1.  1.  1.]\n",
            "len(X): 492 len(y): 492 len(y_hat): 492\n",
            "y_hat: [ 1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1.\n",
            " -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
            " -1.  1. -1. -1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.\n",
            "  1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1. -1. -1.\n",
            "  1. -1.  1. -1.  1.  1.  1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1.\n",
            " -1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1. -1.\n",
            " -1. -1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1. -1. -1.  1. -1.\n",
            "  1. -1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1.\n",
            " -1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.\n",
            " -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1.\n",
            "  1.  1.  1. -1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1.  1.  1.\n",
            "  1. -1. -1.  1.  1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1.  1.\n",
            " -1.  1. -1. -1. -1. -1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1. -1.  1.\n",
            " -1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1. -1.\n",
            " -1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1.  1. -1.\n",
            " -1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1. -1.\n",
            "  1.  1. -1. -1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.\n",
            " -1.  1.  1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
            " -1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1.\n",
            " -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.  1. -1.  1. -1.  1. -1. -1. -1.\n",
            " -1. -1.  1. -1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1.\n",
            " -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.\n",
            " -1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1.  1. -1.\n",
            "  1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1. -1.  1. -1.\n",
            " -1. -1. -1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1.  1.\n",
            " -1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1. -1. -1. -1. -1.  1.\n",
            " -1.  1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.  1.  1. -1. -1.\n",
            "  1.  1.  1.  1.  1. -1.]\n",
            "scores: 0.2145696877549716\n"
          ]
        }
      ],
      "source": [
        "#TODO: k-fold cross validation with a learning rate of 0.10\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, balanced_accuracy_score # balanced_accuracy_score with adjusted=True is Informedness\n",
        "\n",
        "epoch_range = [1]\n",
        "\n",
        "for i in epoch_range:\n",
        "    # Create a new perceptron instance for each epoch\n",
        "    clf = custom_perceptron(alpha=0.1, epochs=i)\n",
        "\n",
        "    # Create the pipeline\n",
        "    pipe = make_pipeline(StandardScaler(), clf)\n",
        "\n",
        "    # Perform cross-validation using the pipeline\n",
        "    cv = KFold(n_splits=5, shuffle=True)\n",
        "    scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring='matthews_corrcoef')\n",
        "    print(f\"scores: {scores.mean()}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLyn_YOiU5gR"
      },
      "source": [
        "Choose a normalization/standardization strategy to apply to the diabetes training data. Using k-fold cross validation and plot the cross validation accuracy and MCC as a function of the number of training epochs.  Repeat for learning rates of 0.90, 0.50, 0.10, 0.01, and 0.0001."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xhd_xx5iYKMa"
      },
      "outputs": [],
      "source": [
        "#TODO: k-fold cross validation on normalized/standardized data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anoQ-Q0CYWZH"
      },
      "source": [
        "How does the normalization/standardization affect the accuracy and MCC scores and number of training epochs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9L9BztuYsz0"
      },
      "source": [
        "Answer in this text box"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdPcCan-YzYP"
      },
      "source": [
        "On the scaled data, for each learning rate, how many training epochs are needed to acheive maximize the accuracy and MCC scores?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kxB29z1ZGhV"
      },
      "source": [
        "Answer in this text box"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7VgxFqSZIrS"
      },
      "source": [
        "Is there a correlation between learning rates and the number of training epochs needed to acheive the optimal results?  If so, what is the correlation?  If not, why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH9-eXOYZx78"
      },
      "source": [
        "Answer in this text box"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helpful resources:\n",
        "* https://towardsdatascience.com/how-to-build-a-custom-estimator-for-scikit-learn-fddc0cb9e16e\n",
        "* Trying to handle the scoring error: https://ubc-cs.github.io/cpsc330-2023W1/lectures/class_demos/05-06_class-demo.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
